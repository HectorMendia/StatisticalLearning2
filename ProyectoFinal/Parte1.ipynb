{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red neuronal feed forward/MLP\n",
    "\n",
    "\n",
    "**Objetivo:** predecir el tipo de movilidad utilizada (walk, train, taxi, etc) utilizada por los usuarios en sus recorridos por medio de la informacion GPS recolectada.\n",
    "\n",
    "\n",
    "Los datos orginales son de un formato PLT:\n",
    "\n",
    "* Line 1â€¦6 are useless in this dataset, and can be ignored. Points are described in following lines, one for each line.\n",
    "* Field 1: Latitude in decimal degrees.\n",
    "* Field 2: Longitude in decimal degrees.\n",
    "* Field 3: All set to 0 for this dataset.\n",
    "* Field 4: Altitude in feet (-777 if not valid).\n",
    "* Field 5: Date - number of days (with fractional part) that have passed since 12/30/1899.\n",
    "* Field 6: Date as a string.\n",
    "* Field 7: Time as a string.\n",
    "\n",
    "\n",
    "* Number of users: 182\n",
    "* Number of trajectories: 18,670\n",
    "* Number of points: 24,876,978\n",
    "* Total distance: 1,292,951km\n",
    "* Total duration: 50,176hour\n",
    "\n",
    "De esta informacion solo se tomo la que esta clasificada en su tipo de ruta.  Adicionalmente se realizo Feature Engineering, para procesar los datos y adecuar la entrada para el modelo MLP. Siendo la estructura inicial del modelo:\n",
    "\n",
    "* StartDate\n",
    "* EndDate\n",
    "* Type\n",
    "* StarDifAprox\n",
    "* EndDifAprox\n",
    "* xStart\n",
    "* yStart\n",
    "* xEnd\n",
    "* yEnd\n",
    "\n",
    "\n",
    "\n",
    "Referencia del dataset\n",
    "https://www.microsoft.com/en-us/download/details.aspx?id=52367&from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fdownloads%2Fb16d359d-d164-469e-9fd4-daa38f2b2e13%2F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Type</th>\n",
       "      <th>StarDifAprox</th>\n",
       "      <th>EndDifAprox</th>\n",
       "      <th>xStart</th>\n",
       "      <th>yStart</th>\n",
       "      <th>xEnd</th>\n",
       "      <th>yEnd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6/26/2007 11:32</td>\n",
       "      <td>6/26/2007 11:40</td>\n",
       "      <td>bus</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3/28/2008 14:52</td>\n",
       "      <td>3/28/2008 15:59</td>\n",
       "      <td>train</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>39.893397</td>\n",
       "      <td>116.313677</td>\n",
       "      <td>39.502930</td>\n",
       "      <td>116.714948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/28/2008 16:00</td>\n",
       "      <td>3/28/2008 22:02</td>\n",
       "      <td>train</td>\n",
       "      <td>1.983333</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>39.489695</td>\n",
       "      <td>116.740047</td>\n",
       "      <td>36.671463</td>\n",
       "      <td>116.988268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3/29/2008 1:27</td>\n",
       "      <td>3/29/2008 15:59</td>\n",
       "      <td>train</td>\n",
       "      <td>5.383333</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>36.661265</td>\n",
       "      <td>116.956267</td>\n",
       "      <td>34.490502</td>\n",
       "      <td>109.629697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3/29/2008 16:00</td>\n",
       "      <td>3/30/2008 15:59</td>\n",
       "      <td>train</td>\n",
       "      <td>1.783333</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>34.495633</td>\n",
       "      <td>109.605400</td>\n",
       "      <td>41.137635</td>\n",
       "      <td>95.465557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         StartDate          EndDate   Type  StarDifAprox  EndDifAprox  \\\n",
       "0  6/26/2007 11:32  6/26/2007 11:40    bus    500.000000   500.000000   \n",
       "1  3/28/2008 14:52  3/28/2008 15:59  train      4.500000     0.033333   \n",
       "2  3/28/2008 16:00  3/28/2008 22:02  train      1.983333     0.683333   \n",
       "3   3/29/2008 1:27  3/29/2008 15:59  train      5.383333     0.183333   \n",
       "4  3/29/2008 16:00  3/30/2008 15:59  train      1.783333     0.316667   \n",
       "\n",
       "      xStart      yStart       xEnd        yEnd  \n",
       "0   0.000000    0.000000   0.000000    0.000000  \n",
       "1  39.893397  116.313677  39.502930  116.714948  \n",
       "2  39.489695  116.740047  36.671463  116.988268  \n",
       "3  36.661265  116.956267  34.490502  109.629697  \n",
       "4  34.495633  109.605400  41.137635   95.465557  "
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data2x.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StarDifAprox</th>\n",
       "      <th>EndDifAprox</th>\n",
       "      <th>xStart</th>\n",
       "      <th>yStart</th>\n",
       "      <th>xEnd</th>\n",
       "      <th>yEnd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21396.000000</td>\n",
       "      <td>21396.000000</td>\n",
       "      <td>21396.000000</td>\n",
       "      <td>21396.000000</td>\n",
       "      <td>21396.000000</td>\n",
       "      <td>21396.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>132.254275</td>\n",
       "      <td>127.406345</td>\n",
       "      <td>29.370248</td>\n",
       "      <td>85.682312</td>\n",
       "      <td>29.370248</td>\n",
       "      <td>85.682312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>219.926409</td>\n",
       "      <td>217.777318</td>\n",
       "      <td>17.450038</td>\n",
       "      <td>51.445871</td>\n",
       "      <td>17.450038</td>\n",
       "      <td>51.445871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-122.303127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-122.303127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.958219</td>\n",
       "      <td>116.328717</td>\n",
       "      <td>39.958219</td>\n",
       "      <td>116.328717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>39.981748</td>\n",
       "      <td>116.406566</td>\n",
       "      <td>39.981748</td>\n",
       "      <td>116.406566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>55.835753</td>\n",
       "      <td>174.391982</td>\n",
       "      <td>55.835753</td>\n",
       "      <td>174.391982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       StarDifAprox   EndDifAprox        xStart        yStart          xEnd  \\\n",
       "count  21396.000000  21396.000000  21396.000000  21396.000000  21396.000000   \n",
       "mean     132.254275    127.406345     29.370248     85.682312     29.370248   \n",
       "std      219.926409    217.777318     17.450038     51.445871     17.450038   \n",
       "min        0.000000      0.000000      0.000000   -122.303127      0.000000   \n",
       "25%        0.016667      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.166667      0.000000     39.958219    116.328717     39.958219   \n",
       "75%      500.000000    500.000000     39.981748    116.406566     39.981748   \n",
       "max      500.000000    500.000000     55.835753    174.391982     55.835753   \n",
       "\n",
       "               yEnd  \n",
       "count  21396.000000  \n",
       "mean      85.682312  \n",
       "std       51.445871  \n",
       "min     -122.303127  \n",
       "25%        0.000000  \n",
       "50%      116.328717  \n",
       "75%      116.406566  \n",
       "max      174.391982  "
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpieza de datos no validos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Type</th>\n",
       "      <th>StarDifAprox</th>\n",
       "      <th>EndDifAprox</th>\n",
       "      <th>xStart</th>\n",
       "      <th>yStart</th>\n",
       "      <th>xEnd</th>\n",
       "      <th>yEnd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3/28/2008 14:52</td>\n",
       "      <td>3/28/2008 15:59</td>\n",
       "      <td>train</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>39.893397</td>\n",
       "      <td>116.313677</td>\n",
       "      <td>39.502930</td>\n",
       "      <td>116.714948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/28/2008 16:00</td>\n",
       "      <td>3/28/2008 22:02</td>\n",
       "      <td>train</td>\n",
       "      <td>1.983333</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>39.489695</td>\n",
       "      <td>116.740047</td>\n",
       "      <td>36.671463</td>\n",
       "      <td>116.988268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3/29/2008 1:27</td>\n",
       "      <td>3/29/2008 15:59</td>\n",
       "      <td>train</td>\n",
       "      <td>5.383333</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>36.661265</td>\n",
       "      <td>116.956267</td>\n",
       "      <td>34.490502</td>\n",
       "      <td>109.629697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3/29/2008 16:00</td>\n",
       "      <td>3/30/2008 15:59</td>\n",
       "      <td>train</td>\n",
       "      <td>1.783333</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>34.495633</td>\n",
       "      <td>109.605400</td>\n",
       "      <td>41.137635</td>\n",
       "      <td>95.465557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3/30/2008 16:00</td>\n",
       "      <td>3/31/2008 3:13</td>\n",
       "      <td>train</td>\n",
       "      <td>1.633333</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>41.153458</td>\n",
       "      <td>95.444897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3/31/2008 4:17</td>\n",
       "      <td>3/31/2008 15:31</td>\n",
       "      <td>train</td>\n",
       "      <td>2.883333</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>43.774235</td>\n",
       "      <td>87.586467</td>\n",
       "      <td>41.744755</td>\n",
       "      <td>86.194410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3/31/2008 16:00</td>\n",
       "      <td>3/31/2008 16:09</td>\n",
       "      <td>taxi</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.737063</td>\n",
       "      <td>86.179470</td>\n",
       "      <td>41.758855</td>\n",
       "      <td>86.144468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3/31/2008 17:26</td>\n",
       "      <td>4/1/2008 0:35</td>\n",
       "      <td>train</td>\n",
       "      <td>1.383333</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>41.746302</td>\n",
       "      <td>86.192568</td>\n",
       "      <td>41.142970</td>\n",
       "      <td>80.304102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4/1/2008 0:48</td>\n",
       "      <td>4/1/2008 0:59</td>\n",
       "      <td>taxi</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.142140</td>\n",
       "      <td>80.286858</td>\n",
       "      <td>41.169595</td>\n",
       "      <td>80.262703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4/1/2008 1:00</td>\n",
       "      <td>4/1/2008 1:08</td>\n",
       "      <td>walk</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.169568</td>\n",
       "      <td>80.263422</td>\n",
       "      <td>41.170472</td>\n",
       "      <td>80.264645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          StartDate          EndDate   Type  StarDifAprox  EndDifAprox  \\\n",
       "1   3/28/2008 14:52  3/28/2008 15:59  train      4.500000     0.033333   \n",
       "2   3/28/2008 16:00  3/28/2008 22:02  train      1.983333     0.683333   \n",
       "3    3/29/2008 1:27  3/29/2008 15:59  train      5.383333     0.183333   \n",
       "4   3/29/2008 16:00  3/30/2008 15:59  train      1.783333     0.316667   \n",
       "5   3/30/2008 16:00   3/31/2008 3:13  train      1.633333   500.000000   \n",
       "6    3/31/2008 4:17  3/31/2008 15:31  train      2.883333     0.233333   \n",
       "7   3/31/2008 16:00  3/31/2008 16:09   taxi      0.983333     0.000000   \n",
       "8   3/31/2008 17:26    4/1/2008 0:35  train      1.383333     0.233333   \n",
       "9     4/1/2008 0:48    4/1/2008 0:59   taxi      0.983333     0.000000   \n",
       "10    4/1/2008 1:00    4/1/2008 1:08   walk      1.000000     0.000000   \n",
       "\n",
       "       xStart      yStart       xEnd        yEnd  \n",
       "1   39.893397  116.313677  39.502930  116.714948  \n",
       "2   39.489695  116.740047  36.671463  116.988268  \n",
       "3   36.661265  116.956267  34.490502  109.629697  \n",
       "4   34.495633  109.605400  41.137635   95.465557  \n",
       "5   41.153458   95.444897   0.000000    0.000000  \n",
       "6   43.774235   87.586467  41.744755   86.194410  \n",
       "7   41.737063   86.179470  41.758855   86.144468  \n",
       "8   41.746302   86.192568  41.142970   80.304102  \n",
       "9   41.142140   80.286858  41.169595   80.262703  \n",
       "10  41.169568   80.263422  41.170472   80.264645  "
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid = df[(df['StarDifAprox']!=500) | (df['EndDifAprox']!=500)]\n",
    "valid.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorias del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['train', 'taxi', 'walk', 'bus', 'subway', 'airplane', 'car',\n",
       "       'bike', 'boat', 'run', 'motorcycle'], dtype=object)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.Type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiempoMin(fec1,fec2):\n",
    "    val = datetime.datetime.strptime(fec2, '%m/%d/%Y %H:%M') - datetime.datetime.strptime(fec1, '%m/%d/%Y %H:%M')\n",
    "    val = val.days * 24 *60 + val.seconds/60\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hecto\\AppData\\Local\\Programs\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "valid['Tiempo'] = valid.apply(lambda row: \n",
    "                        tiempoMin(row.StartDate, row.EndDate), \n",
    "                        axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Type</th>\n",
       "      <th>StarDifAprox</th>\n",
       "      <th>EndDifAprox</th>\n",
       "      <th>xStart</th>\n",
       "      <th>yStart</th>\n",
       "      <th>xEnd</th>\n",
       "      <th>yEnd</th>\n",
       "      <th>Tiempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3/28/2008 14:52</td>\n",
       "      <td>3/28/2008 15:59</td>\n",
       "      <td>train</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>39.893397</td>\n",
       "      <td>116.313677</td>\n",
       "      <td>39.502930</td>\n",
       "      <td>116.714948</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/28/2008 16:00</td>\n",
       "      <td>3/28/2008 22:02</td>\n",
       "      <td>train</td>\n",
       "      <td>1.983333</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>39.489695</td>\n",
       "      <td>116.740047</td>\n",
       "      <td>36.671463</td>\n",
       "      <td>116.988268</td>\n",
       "      <td>362.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3/29/2008 1:27</td>\n",
       "      <td>3/29/2008 15:59</td>\n",
       "      <td>train</td>\n",
       "      <td>5.383333</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>36.661265</td>\n",
       "      <td>116.956267</td>\n",
       "      <td>34.490502</td>\n",
       "      <td>109.629697</td>\n",
       "      <td>872.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3/29/2008 16:00</td>\n",
       "      <td>3/30/2008 15:59</td>\n",
       "      <td>train</td>\n",
       "      <td>1.783333</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>34.495633</td>\n",
       "      <td>109.605400</td>\n",
       "      <td>41.137635</td>\n",
       "      <td>95.465557</td>\n",
       "      <td>1439.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3/30/2008 16:00</td>\n",
       "      <td>3/31/2008 3:13</td>\n",
       "      <td>train</td>\n",
       "      <td>1.633333</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>41.153458</td>\n",
       "      <td>95.444897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>673.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21186</th>\n",
       "      <td>7/19/2007 13:36</td>\n",
       "      <td>7/19/2007 13:57</td>\n",
       "      <td>bike</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.967150</td>\n",
       "      <td>116.344983</td>\n",
       "      <td>39.974933</td>\n",
       "      <td>116.330000</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21187</th>\n",
       "      <td>7/19/2007 13:58</td>\n",
       "      <td>7/19/2007 14:30</td>\n",
       "      <td>walk</td>\n",
       "      <td>2.950000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>39.966950</td>\n",
       "      <td>116.344900</td>\n",
       "      <td>39.967183</td>\n",
       "      <td>116.344633</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21188</th>\n",
       "      <td>7/20/2007 1:38</td>\n",
       "      <td>7/20/2007 1:40</td>\n",
       "      <td>walk</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.966333</td>\n",
       "      <td>116.344100</td>\n",
       "      <td>39.965617</td>\n",
       "      <td>116.343750</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21189</th>\n",
       "      <td>7/20/2007 1:40</td>\n",
       "      <td>7/20/2007 1:49</td>\n",
       "      <td>taxi</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.976950</td>\n",
       "      <td>116.330867</td>\n",
       "      <td>39.966400</td>\n",
       "      <td>116.344233</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21195</th>\n",
       "      <td>7/31/2007 1:55</td>\n",
       "      <td>7/31/2007 1:59</td>\n",
       "      <td>walk</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>39.976567</td>\n",
       "      <td>116.330533</td>\n",
       "      <td>39.976950</td>\n",
       "      <td>116.329783</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16108 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             StartDate          EndDate   Type  StarDifAprox  EndDifAprox  \\\n",
       "1      3/28/2008 14:52  3/28/2008 15:59  train      4.500000     0.033333   \n",
       "2      3/28/2008 16:00  3/28/2008 22:02  train      1.983333     0.683333   \n",
       "3       3/29/2008 1:27  3/29/2008 15:59  train      5.383333     0.183333   \n",
       "4      3/29/2008 16:00  3/30/2008 15:59  train      1.783333     0.316667   \n",
       "5      3/30/2008 16:00   3/31/2008 3:13  train      1.633333   500.000000   \n",
       "...                ...              ...    ...           ...          ...   \n",
       "21186  7/19/2007 13:36  7/19/2007 13:57   bike      0.400000     0.000000   \n",
       "21187  7/19/2007 13:58  7/19/2007 14:30   walk      2.950000     0.033333   \n",
       "21188   7/20/2007 1:38   7/20/2007 1:40   walk      0.000000     0.000000   \n",
       "21189   7/20/2007 1:40   7/20/2007 1:49   taxi      0.000000     0.000000   \n",
       "21195   7/31/2007 1:55   7/31/2007 1:59   walk      0.000000     2.500000   \n",
       "\n",
       "          xStart      yStart       xEnd        yEnd  Tiempo  \n",
       "1      39.893397  116.313677  39.502930  116.714948    67.0  \n",
       "2      39.489695  116.740047  36.671463  116.988268   362.0  \n",
       "3      36.661265  116.956267  34.490502  109.629697   872.0  \n",
       "4      34.495633  109.605400  41.137635   95.465557  1439.0  \n",
       "5      41.153458   95.444897   0.000000    0.000000   673.0  \n",
       "...          ...         ...        ...         ...     ...  \n",
       "21186  39.967150  116.344983  39.974933  116.330000    21.0  \n",
       "21187  39.966950  116.344900  39.967183  116.344633    32.0  \n",
       "21188  39.966333  116.344100  39.965617  116.343750     2.0  \n",
       "21189  39.976950  116.330867  39.966400  116.344233     9.0  \n",
       "21195  39.976567  116.330533  39.976950  116.329783     4.0  \n",
       "\n",
       "[16108 rows x 10 columns]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>xStart</th>\n",
       "      <th>yStart</th>\n",
       "      <th>xEnd</th>\n",
       "      <th>yEnd</th>\n",
       "      <th>Tiempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>39.893397</td>\n",
       "      <td>116.313677</td>\n",
       "      <td>39.502930</td>\n",
       "      <td>116.714948</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>39.489695</td>\n",
       "      <td>116.740047</td>\n",
       "      <td>36.671463</td>\n",
       "      <td>116.988268</td>\n",
       "      <td>362.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>36.661265</td>\n",
       "      <td>116.956267</td>\n",
       "      <td>34.490502</td>\n",
       "      <td>109.629697</td>\n",
       "      <td>872.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>34.495633</td>\n",
       "      <td>109.605400</td>\n",
       "      <td>41.137635</td>\n",
       "      <td>95.465557</td>\n",
       "      <td>1439.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train</td>\n",
       "      <td>41.153458</td>\n",
       "      <td>95.444897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>673.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train</td>\n",
       "      <td>43.774235</td>\n",
       "      <td>87.586467</td>\n",
       "      <td>41.744755</td>\n",
       "      <td>86.194410</td>\n",
       "      <td>674.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>taxi</td>\n",
       "      <td>41.737063</td>\n",
       "      <td>86.179470</td>\n",
       "      <td>41.758855</td>\n",
       "      <td>86.144468</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>train</td>\n",
       "      <td>41.746302</td>\n",
       "      <td>86.192568</td>\n",
       "      <td>41.142970</td>\n",
       "      <td>80.304102</td>\n",
       "      <td>429.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>taxi</td>\n",
       "      <td>41.142140</td>\n",
       "      <td>80.286858</td>\n",
       "      <td>41.169595</td>\n",
       "      <td>80.262703</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>walk</td>\n",
       "      <td>41.169568</td>\n",
       "      <td>80.263422</td>\n",
       "      <td>41.170472</td>\n",
       "      <td>80.264645</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Type     xStart      yStart       xEnd        yEnd  Tiempo\n",
       "1   train  39.893397  116.313677  39.502930  116.714948    67.0\n",
       "2   train  39.489695  116.740047  36.671463  116.988268   362.0\n",
       "3   train  36.661265  116.956267  34.490502  109.629697   872.0\n",
       "4   train  34.495633  109.605400  41.137635   95.465557  1439.0\n",
       "5   train  41.153458   95.444897   0.000000    0.000000   673.0\n",
       "6   train  43.774235   87.586467  41.744755   86.194410   674.0\n",
       "7    taxi  41.737063   86.179470  41.758855   86.144468     9.0\n",
       "8   train  41.746302   86.192568  41.142970   80.304102   429.0\n",
       "9    taxi  41.142140   80.286858  41.169595   80.262703    11.0\n",
       "10   walk  41.169568   80.263422  41.170472   80.264645     8.0"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remover columnas no necesarias (explicadas en las notas de feature eng)\n",
    "del valid[\"StarDifAprox\"] # utilizada en el procesamiento y ya no es necesaria\n",
    "del valid[\"EndDifAprox\"] # utilizada en el procesamiento y ya no es necesaria\n",
    "\n",
    "del valid[\"StartDate\"] # Hora inicial se combina con la final para forma tiempo total del viaje\n",
    "del valid[\"EndDate\"]\n",
    "valid.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid['Type'] = pd.factorize(valid['Type'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = valid[['Type']]\n",
    "X = valid[['xStart','yStart','xEnd','yEnd','Tiempo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tipo__airplane</th>\n",
       "      <th>tipo__bike</th>\n",
       "      <th>tipo__boat</th>\n",
       "      <th>tipo__bus</th>\n",
       "      <th>tipo__car</th>\n",
       "      <th>tipo__motorcycle</th>\n",
       "      <th>tipo__run</th>\n",
       "      <th>tipo__subway</th>\n",
       "      <th>tipo__taxi</th>\n",
       "      <th>tipo__train</th>\n",
       "      <th>tipo__walk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21186</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21187</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21188</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21189</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21195</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16108 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tipo__airplane  tipo__bike  tipo__boat  tipo__bus  tipo__car  \\\n",
       "1                   0           0           0          0          0   \n",
       "2                   0           0           0          0          0   \n",
       "3                   0           0           0          0          0   \n",
       "4                   0           0           0          0          0   \n",
       "5                   0           0           0          0          0   \n",
       "...               ...         ...         ...        ...        ...   \n",
       "21186               0           1           0          0          0   \n",
       "21187               0           0           0          0          0   \n",
       "21188               0           0           0          0          0   \n",
       "21189               0           0           0          0          0   \n",
       "21195               0           0           0          0          0   \n",
       "\n",
       "       tipo__motorcycle  tipo__run  tipo__subway  tipo__taxi  tipo__train  \\\n",
       "1                     0          0             0           0            1   \n",
       "2                     0          0             0           0            1   \n",
       "3                     0          0             0           0            1   \n",
       "4                     0          0             0           0            1   \n",
       "5                     0          0             0           0            1   \n",
       "...                 ...        ...           ...         ...          ...   \n",
       "21186                 0          0             0           0            0   \n",
       "21187                 0          0             0           0            0   \n",
       "21188                 0          0             0           0            0   \n",
       "21189                 0          0             0           1            0   \n",
       "21195                 0          0             0           0            0   \n",
       "\n",
       "       tipo__walk  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "5               0  \n",
       "...           ...  \n",
       "21186           0  \n",
       "21187           1  \n",
       "21188           1  \n",
       "21189           0  \n",
       "21195           1  \n",
       "\n",
       "[16108 rows x 11 columns]"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encoding\n",
    "labels_hot = pd.get_dummies(Y, prefix='tipo_')\n",
    "labels_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tipo__airplane</th>\n",
       "      <th>tipo__bike</th>\n",
       "      <th>tipo__boat</th>\n",
       "      <th>tipo__bus</th>\n",
       "      <th>tipo__car</th>\n",
       "      <th>tipo__motorcycle</th>\n",
       "      <th>tipo__run</th>\n",
       "      <th>tipo__subway</th>\n",
       "      <th>tipo__taxi</th>\n",
       "      <th>tipo__train</th>\n",
       "      <th>tipo__walk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16108.000000</td>\n",
       "      <td>16108.000000</td>\n",
       "      <td>16108.000000</td>\n",
       "      <td>16108.000000</td>\n",
       "      <td>16108.000000</td>\n",
       "      <td>16108.000000</td>\n",
       "      <td>16108.000000</td>\n",
       "      <td>16108.000000</td>\n",
       "      <td>16108.000000</td>\n",
       "      <td>16108.000000</td>\n",
       "      <td>16108.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.001614</td>\n",
       "      <td>0.145021</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.206109</td>\n",
       "      <td>0.093246</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.069531</td>\n",
       "      <td>0.050658</td>\n",
       "      <td>0.020363</td>\n",
       "      <td>0.411969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.040145</td>\n",
       "      <td>0.352133</td>\n",
       "      <td>0.029469</td>\n",
       "      <td>0.404522</td>\n",
       "      <td>0.290785</td>\n",
       "      <td>0.011142</td>\n",
       "      <td>0.022281</td>\n",
       "      <td>0.254362</td>\n",
       "      <td>0.219305</td>\n",
       "      <td>0.141241</td>\n",
       "      <td>0.492205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tipo__airplane    tipo__bike    tipo__boat     tipo__bus     tipo__car  \\\n",
       "count    16108.000000  16108.000000  16108.000000  16108.000000  16108.000000   \n",
       "mean         0.001614      0.145021      0.000869      0.206109      0.093246   \n",
       "std          0.040145      0.352133      0.029469      0.404522      0.290785   \n",
       "min          0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%          0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%          0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%          0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max          1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       tipo__motorcycle     tipo__run  tipo__subway    tipo__taxi  \\\n",
       "count      16108.000000  16108.000000  16108.000000  16108.000000   \n",
       "mean           0.000124      0.000497      0.069531      0.050658   \n",
       "std            0.011142      0.022281      0.254362      0.219305   \n",
       "min            0.000000      0.000000      0.000000      0.000000   \n",
       "25%            0.000000      0.000000      0.000000      0.000000   \n",
       "50%            0.000000      0.000000      0.000000      0.000000   \n",
       "75%            0.000000      0.000000      0.000000      0.000000   \n",
       "max            1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "        tipo__train    tipo__walk  \n",
       "count  16108.000000  16108.000000  \n",
       "mean       0.020363      0.411969  \n",
       "std        0.141241      0.492205  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      0.000000  \n",
       "50%        0.000000      0.000000  \n",
       "75%        0.000000      1.000000  \n",
       "max        1.000000      1.000000  "
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_hot.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16566806,  0.14124292,  0.09227285,  0.16388437,  0.24266175],\n",
       "       [ 0.0897851 ,  0.16530057, -0.43995169,  0.17930628,  3.2859148 ],\n",
       "       [-0.44186858,  0.17750064, -0.84990206, -0.23589631,  8.54713195],\n",
       "       ...,\n",
       "       [ 0.17937774,  0.14295952,  0.17924303,  0.14293977, -0.42788553],\n",
       "       [ 0.18137333,  0.14221284,  0.17939027,  0.14296704, -0.35567275],\n",
       "       [ 0.18130128,  0.14219402,  0.18137333,  0.14215171, -0.40725331]])"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalizacion = MinMaxScaler(feature_range=(0, 1))\n",
    "normalizacion = StandardScaler()\n",
    "xin = normalizacion.fit_transform(X)\n",
    "xin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16108, 5), (16108, 11))"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xin.shape, labels_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,BatchNormalization\n",
    "from keras import initializers\n",
    "from keras import backend as K\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8604973484605801500\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3059115622\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 926748153655774809\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1650 with Max-Q Design, pci bus id: 0000:02:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_input = xx1.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realizaron diversas pruebas con las funciones de activacion y devido a que se tienen valores negativos en la entrada la funcion **tanh** fue la que genero mejores resultados.\n",
    "\n",
    "Como inicializacion se esta utilizando Xavier por medio de **RandomNormal**\n",
    "\n",
    "El **BatchNormalization** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicion de Aquitectura\n",
    "mlp1 = Sequential()\n",
    "mlp1.add(Dense(64,\n",
    "               input_dim=cols_input, \n",
    "               activation='tanh',\n",
    "               kernel_initializer=initializers.RandomNormal(stddev=0.3),\n",
    "               #kernel_initializer=initializers.RandomNormal(),\n",
    "               bias_initializer=initializers.Zeros(),\n",
    "               name=\"layer1\"))\n",
    "mlp1.add(BatchNormalization(momentum=0.09, epsilon=0.001))\n",
    "mlp1.add(Dense(64, activation='tanh',kernel_initializer=initializers.RandomNormal(stddev=0.3),bias_initializer=initializers.Zeros()))\n",
    "mlp1.add(BatchNormalization(momentum=0.09, epsilon=0.001))\n",
    "mlp1.add(Dense(64, activation='tanh',kernel_initializer=initializers.RandomNormal(stddev=0.3),bias_initializer=initializers.Zeros()))\n",
    "mlp1.add(BatchNormalization(momentum=0.09, epsilon=0.001))\n",
    "mlp1.add(Dense(32, activation='tanh',kernel_initializer=initializers.RandomNormal(stddev=0.1),bias_initializer=initializers.Zeros()))\n",
    "mlp1.add(BatchNormalization(momentum=0.09, epsilon=0.001))\n",
    "mlp1.add(Dense(16, activation='tanh',kernel_initializer=initializers.RandomNormal(stddev=0.1),bias_initializer=initializers.Zeros()))\n",
    "mlp1.add(BatchNormalization(momentum=0.09, epsilon=0.001))\n",
    "mlp1.add(Dense(11, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la optimizacion se selecciono **Adam** con una configuracion que se considero que responde mejor a los datos de entrada\n",
    "\n",
    "El tipo de loss es **Categorical Cross Entropy** debido a que es un problema de clasificacion multiclase y los datos *Y* estan como one-hot encoding \n",
    "\n",
    "Se presentan las mediciones de **F1**, **precision** y **recall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSprop\n",
    "#adam\n",
    "#adagrad\n",
    "#opt = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.09)\n",
    "#loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "#opt = tf.keras.optimizers.Adam(learning_rate=0.0005,amsgrad=True)\n",
    "\n",
    "mlp1.compile(optimizer='adam',\n",
    "             #loss = 'categorical_crossentropy',\n",
    "             loss=tf.keras.losses.CategoricalCrossentropy(\n",
    "                from_logits=True,\n",
    "                label_smoothing=0,\n",
    "                reduction=\"auto\"),\n",
    "             metrics=['accuracy',f1_m,precision_m, recall_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Dense)               (None, 64)                384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_303 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_304 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_305 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_306 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_307 (Dense)            (None, 11)                187       \n",
      "=================================================================\n",
      "Total params: 12,459\n",
      "Trainable params: 11,979\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12886 samples, validate on 3222 samples\n",
      "Epoch 1/300\n",
      "12886/12886 [==============================] - 3s 219us/step - loss: 1.9141 - accuracy: 0.6286 - f1_m: 0.6284 - precision_m: 0.6305 - recall_m: 0.6264 - val_loss: 1.9600 - val_accuracy: 0.5872 - val_f1_m: 0.5857 - val_precision_m: 0.5868 - val_recall_m: 0.5846\n",
      "Epoch 2/300\n",
      "12886/12886 [==============================] - 2s 174us/step - loss: 1.8921 - accuracy: 0.6509 - f1_m: 0.6510 - precision_m: 0.6525 - recall_m: 0.6495 - val_loss: 1.9326 - val_accuracy: 0.6089 - val_f1_m: 0.6079 - val_precision_m: 0.6093 - val_recall_m: 0.6065\n",
      "Epoch 3/300\n",
      "12886/12886 [==============================] - 2s 171us/step - loss: 1.8884 - accuracy: 0.6545 - f1_m: 0.6547 - precision_m: 0.6564 - recall_m: 0.6531 - val_loss: 1.9592 - val_accuracy: 0.5875 - val_f1_m: 0.5875 - val_precision_m: 0.5884 - val_recall_m: 0.5866\n",
      "Epoch 4/300\n",
      "12886/12886 [==============================] - 2s 178us/step - loss: 1.8824 - accuracy: 0.6603 - f1_m: 0.6599 - precision_m: 0.6617 - recall_m: 0.6582 - val_loss: 1.9530 - val_accuracy: 0.5872 - val_f1_m: 0.5864 - val_precision_m: 0.5874 - val_recall_m: 0.5855\n",
      "Epoch 5/300\n",
      "12886/12886 [==============================] - 2s 187us/step - loss: 1.8743 - accuracy: 0.6689 - f1_m: 0.6695 - precision_m: 0.6710 - recall_m: 0.6680 - val_loss: 1.9450 - val_accuracy: 0.5950 - val_f1_m: 0.5950 - val_precision_m: 0.5968 - val_recall_m: 0.5933\n",
      "Epoch 6/300\n",
      "12886/12886 [==============================] - 2s 184us/step - loss: 1.8761 - accuracy: 0.6671 - f1_m: 0.6666 - precision_m: 0.6682 - recall_m: 0.6652 - val_loss: 1.9621 - val_accuracy: 0.5754 - val_f1_m: 0.5741 - val_precision_m: 0.5749 - val_recall_m: 0.5734\n",
      "Epoch 7/300\n",
      "12886/12886 [==============================] - 2s 180us/step - loss: 1.8769 - accuracy: 0.6651 - f1_m: 0.6655 - precision_m: 0.6669 - recall_m: 0.6641 - val_loss: 1.9123 - val_accuracy: 0.6291 - val_f1_m: 0.6290 - val_precision_m: 0.6312 - val_recall_m: 0.6269\n",
      "Epoch 8/300\n",
      "12886/12886 [==============================] - 2s 187us/step - loss: 1.8766 - accuracy: 0.6677 - f1_m: 0.6680 - precision_m: 0.6701 - recall_m: 0.6660 - val_loss: 2.0034 - val_accuracy: 0.5369 - val_f1_m: 0.5364 - val_precision_m: 0.5386 - val_recall_m: 0.5342\n",
      "Epoch 9/300\n",
      "12886/12886 [==============================] - 2s 183us/step - loss: 1.8760 - accuracy: 0.6674 - f1_m: 0.6676 - precision_m: 0.6691 - recall_m: 0.6661 - val_loss: 1.9760 - val_accuracy: 0.5633 - val_f1_m: 0.5632 - val_precision_m: 0.5647 - val_recall_m: 0.5617\n",
      "Epoch 10/300\n",
      "12886/12886 [==============================] - 3s 198us/step - loss: 1.8737 - accuracy: 0.6709 - f1_m: 0.6707 - precision_m: 0.6720 - recall_m: 0.6694 - val_loss: 1.9706 - val_accuracy: 0.5754 - val_f1_m: 0.5750 - val_precision_m: 0.5772 - val_recall_m: 0.5729\n",
      "Epoch 11/300\n",
      "12886/12886 [==============================] - 3s 201us/step - loss: 1.8741 - accuracy: 0.6710 - f1_m: 0.6709 - precision_m: 0.6723 - recall_m: 0.6696 - val_loss: 1.9924 - val_accuracy: 0.5528 - val_f1_m: 0.5527 - val_precision_m: 0.5531 - val_recall_m: 0.5523\n",
      "Epoch 12/300\n",
      "12886/12886 [==============================] - 2s 192us/step - loss: 1.8706 - accuracy: 0.6732 - f1_m: 0.6735 - precision_m: 0.6755 - recall_m: 0.6716 - val_loss: 1.9377 - val_accuracy: 0.6043 - val_f1_m: 0.6038 - val_precision_m: 0.6060 - val_recall_m: 0.6017\n",
      "Epoch 13/300\n",
      "12886/12886 [==============================] - 3s 210us/step - loss: 1.8689 - accuracy: 0.6750 - f1_m: 0.6754 - precision_m: 0.6769 - recall_m: 0.6739 - val_loss: 2.1062 - val_accuracy: 0.4342 - val_f1_m: 0.4317 - val_precision_m: 0.4340 - val_recall_m: 0.4296\n",
      "Epoch 14/300\n",
      "12886/12886 [==============================] - 3s 204us/step - loss: 1.8748 - accuracy: 0.6679 - f1_m: 0.6683 - precision_m: 0.6703 - recall_m: 0.6664 - val_loss: 1.8968 - val_accuracy: 0.6480 - val_f1_m: 0.6473 - val_precision_m: 0.6485 - val_recall_m: 0.6461\n",
      "Epoch 15/300\n",
      "12886/12886 [==============================] - 3s 197us/step - loss: 1.8702 - accuracy: 0.6731 - f1_m: 0.6737 - precision_m: 0.6753 - recall_m: 0.6722 - val_loss: 1.9239 - val_accuracy: 0.6176 - val_f1_m: 0.6181 - val_precision_m: 0.6207 - val_recall_m: 0.6157\n",
      "Epoch 16/300\n",
      "12886/12886 [==============================] - 3s 196us/step - loss: 1.8732 - accuracy: 0.6703 - f1_m: 0.6705 - precision_m: 0.6722 - recall_m: 0.6688 - val_loss: 1.9370 - val_accuracy: 0.6061 - val_f1_m: 0.6066 - val_precision_m: 0.6081 - val_recall_m: 0.6050\n",
      "Epoch 17/300\n",
      "12886/12886 [==============================] - 2s 193us/step - loss: 1.8752 - accuracy: 0.6682 - f1_m: 0.6687 - precision_m: 0.6704 - recall_m: 0.6670 - val_loss: 2.0525 - val_accuracy: 0.4873 - val_f1_m: 0.4865 - val_precision_m: 0.4880 - val_recall_m: 0.4850\n",
      "Epoch 18/300\n",
      "12886/12886 [==============================] - 3s 202us/step - loss: 1.8743 - accuracy: 0.6703 - f1_m: 0.6702 - precision_m: 0.6720 - recall_m: 0.6684 - val_loss: 1.9022 - val_accuracy: 0.6403 - val_f1_m: 0.6395 - val_precision_m: 0.6398 - val_recall_m: 0.6392\n",
      "Epoch 19/300\n",
      "12886/12886 [==============================] - 3s 196us/step - loss: 1.8714 - accuracy: 0.6731 - f1_m: 0.6728 - precision_m: 0.6742 - recall_m: 0.6715 - val_loss: 2.0662 - val_accuracy: 0.4733 - val_f1_m: 0.4732 - val_precision_m: 0.4751 - val_recall_m: 0.4713\n",
      "Epoch 20/300\n",
      "12886/12886 [==============================] - 3s 200us/step - loss: 1.8744 - accuracy: 0.6694 - f1_m: 0.6691 - precision_m: 0.6706 - recall_m: 0.6677 - val_loss: 1.9826 - val_accuracy: 0.5642 - val_f1_m: 0.5628 - val_precision_m: 0.5638 - val_recall_m: 0.5619\n",
      "Epoch 21/300\n",
      "12886/12886 [==============================] - 3s 204us/step - loss: 1.8715 - accuracy: 0.6720 - f1_m: 0.6722 - precision_m: 0.6742 - recall_m: 0.6704 - val_loss: 1.9306 - val_accuracy: 0.6139 - val_f1_m: 0.6137 - val_precision_m: 0.6151 - val_recall_m: 0.6123\n",
      "Epoch 22/300\n",
      "12886/12886 [==============================] - 3s 217us/step - loss: 1.8701 - accuracy: 0.6731 - f1_m: 0.6730 - precision_m: 0.6746 - recall_m: 0.6715 - val_loss: 1.9300 - val_accuracy: 0.6092 - val_f1_m: 0.6100 - val_precision_m: 0.6120 - val_recall_m: 0.6081\n",
      "Epoch 23/300\n",
      "12886/12886 [==============================] - 3s 204us/step - loss: 1.8745 - accuracy: 0.6686 - f1_m: 0.6688 - precision_m: 0.6706 - recall_m: 0.6671 - val_loss: 2.0102 - val_accuracy: 0.5335 - val_f1_m: 0.5344 - val_precision_m: 0.5370 - val_recall_m: 0.5320\n",
      "Epoch 24/300\n",
      "12886/12886 [==============================] - 2s 193us/step - loss: 1.8690 - accuracy: 0.6745 - f1_m: 0.6744 - precision_m: 0.6759 - recall_m: 0.6729 - val_loss: 1.9286 - val_accuracy: 0.6136 - val_f1_m: 0.6138 - val_precision_m: 0.6165 - val_recall_m: 0.6112\n",
      "Epoch 25/300\n",
      "12886/12886 [==============================] - 2s 192us/step - loss: 1.8689 - accuracy: 0.6752 - f1_m: 0.6752 - precision_m: 0.6767 - recall_m: 0.6738 - val_loss: 1.9081 - val_accuracy: 0.6353 - val_f1_m: 0.6351 - val_precision_m: 0.6370 - val_recall_m: 0.6334\n",
      "Epoch 26/300\n",
      "12886/12886 [==============================] - 3s 207us/step - loss: 1.8718 - accuracy: 0.6718 - f1_m: 0.6716 - precision_m: 0.6733 - recall_m: 0.6700 - val_loss: 1.9171 - val_accuracy: 0.6356 - val_f1_m: 0.6351 - val_precision_m: 0.6362 - val_recall_m: 0.6340\n",
      "Epoch 27/300\n",
      "12886/12886 [==============================] - 3s 202us/step - loss: 1.8677 - accuracy: 0.6765 - f1_m: 0.6764 - precision_m: 0.6780 - recall_m: 0.6748 - val_loss: 1.9638 - val_accuracy: 0.5736 - val_f1_m: 0.5734 - val_precision_m: 0.5748 - val_recall_m: 0.5721\n",
      "Epoch 28/300\n",
      "12886/12886 [==============================] - 3s 207us/step - loss: 1.8678 - accuracy: 0.6750 - f1_m: 0.6752 - precision_m: 0.6770 - recall_m: 0.6735 - val_loss: 1.9352 - val_accuracy: 0.6105 - val_f1_m: 0.6097 - val_precision_m: 0.6114 - val_recall_m: 0.6081\n",
      "Epoch 29/300\n",
      "12886/12886 [==============================] - 3s 199us/step - loss: 1.8729 - accuracy: 0.6700 - f1_m: 0.6694 - precision_m: 0.6708 - recall_m: 0.6681 - val_loss: 1.9277 - val_accuracy: 0.6117 - val_f1_m: 0.6098 - val_precision_m: 0.6118 - val_recall_m: 0.6080\n",
      "Epoch 30/300\n",
      "12886/12886 [==============================] - 2s 192us/step - loss: 1.8677 - accuracy: 0.6771 - f1_m: 0.6777 - precision_m: 0.6793 - recall_m: 0.6761 - val_loss: 1.8661 - val_accuracy: 0.6766 - val_f1_m: 0.6772 - val_precision_m: 0.6783 - val_recall_m: 0.6760\n",
      "Epoch 31/300\n",
      "12886/12886 [==============================] - 3s 203us/step - loss: 1.8663 - accuracy: 0.6784 - f1_m: 0.6784 - precision_m: 0.6798 - recall_m: 0.6771 - val_loss: 1.9329 - val_accuracy: 0.6099 - val_f1_m: 0.6099 - val_precision_m: 0.6113 - val_recall_m: 0.6084\n",
      "Epoch 32/300\n",
      "12886/12886 [==============================] - 3s 198us/step - loss: 1.8682 - accuracy: 0.6764 - f1_m: 0.6766 - precision_m: 0.6784 - recall_m: 0.6749 - val_loss: 1.9302 - val_accuracy: 0.6089 - val_f1_m: 0.6096 - val_precision_m: 0.6127 - val_recall_m: 0.6067\n",
      "Epoch 33/300\n",
      "12886/12886 [==============================] - 3s 198us/step - loss: 1.8683 - accuracy: 0.6752 - f1_m: 0.6758 - precision_m: 0.6775 - recall_m: 0.6742 - val_loss: 2.1997 - val_accuracy: 0.3355 - val_f1_m: 0.3349 - val_precision_m: 0.3367 - val_recall_m: 0.3332\n",
      "Epoch 34/300\n",
      "12886/12886 [==============================] - 3s 196us/step - loss: 1.8654 - accuracy: 0.6783 - f1_m: 0.6784 - precision_m: 0.6805 - recall_m: 0.6764 - val_loss: 1.9569 - val_accuracy: 0.5835 - val_f1_m: 0.5835 - val_precision_m: 0.5844 - val_recall_m: 0.5826\n",
      "Epoch 35/300\n",
      "12886/12886 [==============================] - 3s 200us/step - loss: 1.8672 - accuracy: 0.6749 - f1_m: 0.6753 - precision_m: 0.6768 - recall_m: 0.6738 - val_loss: 2.0044 - val_accuracy: 0.5438 - val_f1_m: 0.5439 - val_precision_m: 0.5454 - val_recall_m: 0.5424\n",
      "Epoch 36/300\n",
      "12886/12886 [==============================] - 3s 194us/step - loss: 1.8661 - accuracy: 0.6774 - f1_m: 0.6780 - precision_m: 0.6798 - recall_m: 0.6764 - val_loss: 1.9115 - val_accuracy: 0.6304 - val_f1_m: 0.6301 - val_precision_m: 0.6311 - val_recall_m: 0.6291\n",
      "Epoch 37/300\n",
      "12886/12886 [==============================] - 3s 200us/step - loss: 1.8605 - accuracy: 0.6828 - f1_m: 0.6832 - precision_m: 0.6848 - recall_m: 0.6817 - val_loss: 1.9221 - val_accuracy: 0.6195 - val_f1_m: 0.6194 - val_precision_m: 0.6214 - val_recall_m: 0.6175\n",
      "Epoch 38/300\n",
      "12886/12886 [==============================] - 3s 198us/step - loss: 1.8646 - accuracy: 0.6786 - f1_m: 0.6787 - precision_m: 0.6803 - recall_m: 0.6772 - val_loss: 2.0260 - val_accuracy: 0.5174 - val_f1_m: 0.5163 - val_precision_m: 0.5190 - val_recall_m: 0.5137\n",
      "Epoch 39/300\n",
      "12886/12886 [==============================] - 3s 202us/step - loss: 1.8665 - accuracy: 0.6771 - f1_m: 0.6775 - precision_m: 0.6791 - recall_m: 0.6760 - val_loss: 2.0066 - val_accuracy: 0.5289 - val_f1_m: 0.5292 - val_precision_m: 0.5305 - val_recall_m: 0.5280\n",
      "Epoch 40/300\n",
      "12886/12886 [==============================] - 3s 203us/step - loss: 1.8679 - accuracy: 0.6765 - f1_m: 0.6766 - precision_m: 0.6784 - recall_m: 0.6749 - val_loss: 1.8979 - val_accuracy: 0.6487 - val_f1_m: 0.6484 - val_precision_m: 0.6514 - val_recall_m: 0.6457\n",
      "Epoch 41/300\n",
      "12886/12886 [==============================] - 3s 207us/step - loss: 1.8654 - accuracy: 0.6779 - f1_m: 0.6788 - precision_m: 0.6803 - recall_m: 0.6773 - val_loss: 1.8744 - val_accuracy: 0.6673 - val_f1_m: 0.6672 - val_precision_m: 0.6685 - val_recall_m: 0.6660\n",
      "Epoch 42/300\n",
      "12886/12886 [==============================] - 3s 202us/step - loss: 1.8654 - accuracy: 0.6779 - f1_m: 0.6783 - precision_m: 0.6799 - recall_m: 0.6768 - val_loss: 1.9577 - val_accuracy: 0.5885 - val_f1_m: 0.5861 - val_precision_m: 0.5883 - val_recall_m: 0.5840\n",
      "Epoch 43/300\n",
      "12886/12886 [==============================] - 3s 207us/step - loss: 1.8674 - accuracy: 0.6767 - f1_m: 0.6768 - precision_m: 0.6784 - recall_m: 0.6752 - val_loss: 1.9885 - val_accuracy: 0.5562 - val_f1_m: 0.5541 - val_precision_m: 0.5557 - val_recall_m: 0.5525\n",
      "Epoch 44/300\n",
      "12886/12886 [==============================] - 3s 213us/step - loss: 1.8610 - accuracy: 0.6826 - f1_m: 0.6828 - precision_m: 0.6844 - recall_m: 0.6813 - val_loss: 1.9428 - val_accuracy: 0.6058 - val_f1_m: 0.6044 - val_precision_m: 0.6072 - val_recall_m: 0.6018\n",
      "Epoch 45/300\n",
      "12886/12886 [==============================] - 3s 203us/step - loss: 1.8686 - accuracy: 0.6749 - f1_m: 0.6751 - precision_m: 0.6767 - recall_m: 0.6736 - val_loss: 1.9166 - val_accuracy: 0.6285 - val_f1_m: 0.6282 - val_precision_m: 0.6300 - val_recall_m: 0.6264\n",
      "Epoch 46/300\n",
      "12886/12886 [==============================] - 3s 197us/step - loss: 1.8661 - accuracy: 0.6781 - f1_m: 0.6776 - precision_m: 0.6793 - recall_m: 0.6759 - val_loss: 1.9957 - val_accuracy: 0.5484 - val_f1_m: 0.5478 - val_precision_m: 0.5493 - val_recall_m: 0.5465\n",
      "Epoch 47/300\n",
      "12886/12886 [==============================] - 3s 199us/step - loss: 1.8617 - accuracy: 0.6828 - f1_m: 0.6818 - precision_m: 0.6836 - recall_m: 0.6801 - val_loss: 1.9474 - val_accuracy: 0.5978 - val_f1_m: 0.5970 - val_precision_m: 0.5994 - val_recall_m: 0.5947\n",
      "Epoch 48/300\n",
      "12886/12886 [==============================] - 3s 197us/step - loss: 1.8608 - accuracy: 0.6842 - f1_m: 0.6841 - precision_m: 0.6856 - recall_m: 0.6826 - val_loss: 1.9245 - val_accuracy: 0.6170 - val_f1_m: 0.6154 - val_precision_m: 0.6181 - val_recall_m: 0.6128\n",
      "Epoch 49/300\n",
      "12886/12886 [==============================] - 3s 199us/step - loss: 1.8623 - accuracy: 0.6824 - f1_m: 0.6825 - precision_m: 0.6839 - recall_m: 0.6812 - val_loss: 1.9084 - val_accuracy: 0.6285 - val_f1_m: 0.6290 - val_precision_m: 0.6300 - val_recall_m: 0.6279\n",
      "Epoch 50/300\n",
      "12886/12886 [==============================] - 3s 198us/step - loss: 1.8595 - accuracy: 0.6843 - f1_m: 0.6848 - precision_m: 0.6860 - recall_m: 0.6836 - val_loss: 2.0198 - val_accuracy: 0.5211 - val_f1_m: 0.5206 - val_precision_m: 0.5230 - val_recall_m: 0.5184\n",
      "Epoch 51/300\n",
      "12886/12886 [==============================] - 3s 200us/step - loss: 1.8576 - accuracy: 0.6861 - f1_m: 0.6866 - precision_m: 0.6881 - recall_m: 0.6850 - val_loss: 1.8960 - val_accuracy: 0.6465 - val_f1_m: 0.6457 - val_precision_m: 0.6469 - val_recall_m: 0.6445\n",
      "Epoch 52/300\n",
      "12886/12886 [==============================] - 3s 199us/step - loss: 1.8582 - accuracy: 0.6849 - f1_m: 0.6851 - precision_m: 0.6868 - recall_m: 0.6835 - val_loss: 1.9185 - val_accuracy: 0.6235 - val_f1_m: 0.6235 - val_precision_m: 0.6247 - val_recall_m: 0.6224\n",
      "Epoch 53/300\n",
      "12886/12886 [==============================] - 3s 203us/step - loss: 1.8610 - accuracy: 0.6843 - f1_m: 0.6842 - precision_m: 0.6857 - recall_m: 0.6826 - val_loss: 1.8890 - val_accuracy: 0.6546 - val_f1_m: 0.6545 - val_precision_m: 0.6552 - val_recall_m: 0.6537\n",
      "Epoch 54/300\n",
      "12886/12886 [==============================] - 3s 209us/step - loss: 1.8617 - accuracy: 0.6812 - f1_m: 0.6814 - precision_m: 0.6827 - recall_m: 0.6801 - val_loss: 2.0760 - val_accuracy: 0.4600 - val_f1_m: 0.4579 - val_precision_m: 0.4604 - val_recall_m: 0.4555\n",
      "Epoch 55/300\n",
      "12886/12886 [==============================] - 3s 197us/step - loss: 1.8654 - accuracy: 0.6780 - f1_m: 0.6782 - precision_m: 0.6797 - recall_m: 0.6768 - val_loss: 1.9829 - val_accuracy: 0.5599 - val_f1_m: 0.5608 - val_precision_m: 0.5627 - val_recall_m: 0.5589\n",
      "Epoch 56/300\n",
      "12886/12886 [==============================] - 2s 187us/step - loss: 1.8666 - accuracy: 0.6764 - f1_m: 0.6769 - precision_m: 0.6784 - recall_m: 0.6755 - val_loss: 1.9714 - val_accuracy: 0.5673 - val_f1_m: 0.5659 - val_precision_m: 0.5675 - val_recall_m: 0.5644\n",
      "Epoch 57/300\n",
      "12886/12886 [==============================] - 2s 191us/step - loss: 1.8582 - accuracy: 0.6847 - f1_m: 0.6849 - precision_m: 0.6863 - recall_m: 0.6836 - val_loss: 2.2068 - val_accuracy: 0.3287 - val_f1_m: 0.3291 - val_precision_m: 0.3304 - val_recall_m: 0.3279\n",
      "Epoch 58/300\n",
      "12886/12886 [==============================] - 2s 193us/step - loss: 1.8612 - accuracy: 0.6819 - f1_m: 0.6814 - precision_m: 0.6832 - recall_m: 0.6798 - val_loss: 2.0048 - val_accuracy: 0.5366 - val_f1_m: 0.5358 - val_precision_m: 0.5371 - val_recall_m: 0.5345\n",
      "Epoch 59/300\n",
      "12886/12886 [==============================] - 3s 206us/step - loss: 1.8627 - accuracy: 0.6813 - f1_m: 0.6818 - precision_m: 0.6834 - recall_m: 0.6803 - val_loss: 1.9081 - val_accuracy: 0.6341 - val_f1_m: 0.6343 - val_precision_m: 0.6356 - val_recall_m: 0.6332\n",
      "Epoch 60/300\n",
      "12886/12886 [==============================] - 3s 206us/step - loss: 1.8600 - accuracy: 0.6824 - f1_m: 0.6829 - precision_m: 0.6843 - recall_m: 0.6815 - val_loss: 1.9391 - val_accuracy: 0.6034 - val_f1_m: 0.6030 - val_precision_m: 0.6044 - val_recall_m: 0.6017\n",
      "Epoch 61/300\n",
      "12886/12886 [==============================] - 2s 193us/step - loss: 1.8591 - accuracy: 0.6856 - f1_m: 0.6861 - precision_m: 0.6875 - recall_m: 0.6848 - val_loss: 1.8744 - val_accuracy: 0.6685 - val_f1_m: 0.6682 - val_precision_m: 0.6695 - val_recall_m: 0.6669\n",
      "Epoch 62/300\n",
      "12886/12886 [==============================] - 3s 197us/step - loss: 1.8577 - accuracy: 0.6852 - f1_m: 0.6850 - precision_m: 0.6864 - recall_m: 0.6837 - val_loss: 1.8951 - val_accuracy: 0.6456 - val_f1_m: 0.6462 - val_precision_m: 0.6480 - val_recall_m: 0.6445\n",
      "Epoch 63/300\n",
      "12886/12886 [==============================] - 2s 194us/step - loss: 1.8617 - accuracy: 0.6811 - f1_m: 0.6814 - precision_m: 0.6827 - recall_m: 0.6801 - val_loss: 1.9060 - val_accuracy: 0.6359 - val_f1_m: 0.6355 - val_precision_m: 0.6364 - val_recall_m: 0.6346\n",
      "Epoch 64/300\n",
      "12886/12886 [==============================] - 2s 187us/step - loss: 1.8594 - accuracy: 0.6842 - f1_m: 0.6840 - precision_m: 0.6857 - recall_m: 0.6824 - val_loss: 1.9240 - val_accuracy: 0.6207 - val_f1_m: 0.6210 - val_precision_m: 0.6224 - val_recall_m: 0.6197\n",
      "Epoch 65/300\n",
      "12886/12886 [==============================] - 3s 199us/step - loss: 1.8662 - accuracy: 0.6769 - f1_m: 0.6768 - precision_m: 0.6780 - recall_m: 0.6757 - val_loss: 1.9963 - val_accuracy: 0.5447 - val_f1_m: 0.5437 - val_precision_m: 0.5452 - val_recall_m: 0.5424\n",
      "Epoch 66/300\n",
      "12886/12886 [==============================] - 3s 206us/step - loss: 1.8584 - accuracy: 0.6850 - f1_m: 0.6855 - precision_m: 0.6868 - recall_m: 0.6841 - val_loss: 1.9436 - val_accuracy: 0.5978 - val_f1_m: 0.5970 - val_precision_m: 0.5982 - val_recall_m: 0.5959\n",
      "Epoch 67/300\n",
      "12886/12886 [==============================] - 2s 193us/step - loss: 1.8607 - accuracy: 0.6835 - f1_m: 0.6838 - precision_m: 0.6852 - recall_m: 0.6824 - val_loss: 1.9403 - val_accuracy: 0.6040 - val_f1_m: 0.6035 - val_precision_m: 0.6063 - val_recall_m: 0.6008\n",
      "Epoch 68/300\n",
      "12886/12886 [==============================] - 2s 192us/step - loss: 1.8615 - accuracy: 0.6836 - f1_m: 0.6837 - precision_m: 0.6854 - recall_m: 0.6822 - val_loss: 1.8984 - val_accuracy: 0.6465 - val_f1_m: 0.6468 - val_precision_m: 0.6481 - val_recall_m: 0.6455\n",
      "Epoch 69/300\n",
      "12886/12886 [==============================] - 3s 201us/step - loss: 1.8574 - accuracy: 0.6859 - f1_m: 0.6860 - precision_m: 0.6873 - recall_m: 0.6847 - val_loss: 1.8917 - val_accuracy: 0.6530 - val_f1_m: 0.6525 - val_precision_m: 0.6532 - val_recall_m: 0.6519\n",
      "Epoch 70/300\n",
      "12886/12886 [==============================] - 3s 197us/step - loss: 1.8602 - accuracy: 0.6828 - f1_m: 0.6831 - precision_m: 0.6847 - recall_m: 0.6815 - val_loss: 2.1049 - val_accuracy: 0.4230 - val_f1_m: 0.4213 - val_precision_m: 0.4232 - val_recall_m: 0.4195\n",
      "Epoch 71/300\n",
      "12886/12886 [==============================] - 2s 192us/step - loss: 1.8561 - accuracy: 0.6875 - f1_m: 0.6875 - precision_m: 0.6891 - recall_m: 0.6859 - val_loss: 1.9251 - val_accuracy: 0.6173 - val_f1_m: 0.6152 - val_precision_m: 0.6170 - val_recall_m: 0.6134\n",
      "Epoch 72/300\n",
      "12886/12886 [==============================] - 3s 202us/step - loss: 1.8614 - accuracy: 0.6820 - f1_m: 0.6822 - precision_m: 0.6838 - recall_m: 0.6807 - val_loss: 1.9049 - val_accuracy: 0.6425 - val_f1_m: 0.6422 - val_precision_m: 0.6429 - val_recall_m: 0.6414\n",
      "Epoch 73/300\n",
      "12886/12886 [==============================] - 3s 196us/step - loss: 1.8562 - accuracy: 0.6876 - f1_m: 0.6878 - precision_m: 0.6893 - recall_m: 0.6864 - val_loss: 1.8732 - val_accuracy: 0.6726 - val_f1_m: 0.6710 - val_precision_m: 0.6731 - val_recall_m: 0.6689\n",
      "Epoch 74/300\n",
      "12886/12886 [==============================] - 2s 190us/step - loss: 1.8597 - accuracy: 0.6824 - f1_m: 0.6827 - precision_m: 0.6843 - recall_m: 0.6812 - val_loss: 1.9168 - val_accuracy: 0.6276 - val_f1_m: 0.6264 - val_precision_m: 0.6279 - val_recall_m: 0.6250\n",
      "Epoch 75/300\n",
      "12886/12886 [==============================] - 2s 193us/step - loss: 1.8558 - accuracy: 0.6882 - f1_m: 0.6885 - precision_m: 0.6897 - recall_m: 0.6873 - val_loss: 1.8913 - val_accuracy: 0.6518 - val_f1_m: 0.6519 - val_precision_m: 0.6536 - val_recall_m: 0.6503\n",
      "Epoch 76/300\n",
      "12886/12886 [==============================] - 3s 198us/step - loss: 1.8556 - accuracy: 0.6876 - f1_m: 0.6877 - precision_m: 0.6891 - recall_m: 0.6865 - val_loss: 1.8835 - val_accuracy: 0.6574 - val_f1_m: 0.6576 - val_precision_m: 0.6592 - val_recall_m: 0.6561\n",
      "Epoch 77/300\n",
      "12886/12886 [==============================] - 3s 202us/step - loss: 1.8564 - accuracy: 0.6862 - f1_m: 0.6866 - precision_m: 0.6881 - recall_m: 0.6852 - val_loss: 1.9361 - val_accuracy: 0.6052 - val_f1_m: 0.6064 - val_precision_m: 0.6091 - val_recall_m: 0.6038\n",
      "Epoch 78/300\n",
      "12886/12886 [==============================] - 3s 199us/step - loss: 1.8547 - accuracy: 0.6898 - f1_m: 0.6899 - precision_m: 0.6911 - recall_m: 0.6887 - val_loss: 1.9754 - val_accuracy: 0.5655 - val_f1_m: 0.5657 - val_precision_m: 0.5672 - val_recall_m: 0.5644\n",
      "Epoch 79/300\n",
      "12886/12886 [==============================] - 3s 209us/step - loss: 1.8583 - accuracy: 0.6859 - f1_m: 0.6854 - precision_m: 0.6867 - recall_m: 0.6840 - val_loss: 1.9693 - val_accuracy: 0.5664 - val_f1_m: 0.5621 - val_precision_m: 0.5658 - val_recall_m: 0.5587\n",
      "Epoch 80/300\n",
      "12886/12886 [==============================] - 3s 206us/step - loss: 1.8545 - accuracy: 0.6906 - f1_m: 0.6910 - precision_m: 0.6920 - recall_m: 0.6900 - val_loss: 1.9774 - val_accuracy: 0.5605 - val_f1_m: 0.5582 - val_precision_m: 0.5606 - val_recall_m: 0.5559\n",
      "Epoch 81/300\n",
      "12886/12886 [==============================] - 3s 199us/step - loss: 1.8532 - accuracy: 0.6901 - f1_m: 0.6900 - precision_m: 0.6911 - recall_m: 0.6888 - val_loss: 1.9672 - val_accuracy: 0.5770 - val_f1_m: 0.5755 - val_precision_m: 0.5763 - val_recall_m: 0.5748\n",
      "Epoch 82/300\n",
      "12886/12886 [==============================] - 3s 205us/step - loss: 1.8555 - accuracy: 0.6881 - f1_m: 0.6881 - precision_m: 0.6897 - recall_m: 0.6866 - val_loss: 1.8783 - val_accuracy: 0.6682 - val_f1_m: 0.6681 - val_precision_m: 0.6694 - val_recall_m: 0.6669\n",
      "Epoch 83/300\n",
      "12886/12886 [==============================] - 3s 228us/step - loss: 1.8543 - accuracy: 0.6890 - f1_m: 0.6887 - precision_m: 0.6902 - recall_m: 0.6873 - val_loss: 1.9835 - val_accuracy: 0.5571 - val_f1_m: 0.5553 - val_precision_m: 0.5580 - val_recall_m: 0.5527\n",
      "Epoch 84/300\n",
      "12886/12886 [==============================] - 3s 207us/step - loss: 1.8524 - accuracy: 0.6917 - f1_m: 0.6920 - precision_m: 0.6934 - recall_m: 0.6906 - val_loss: 1.9819 - val_accuracy: 0.5549 - val_f1_m: 0.5526 - val_precision_m: 0.5537 - val_recall_m: 0.5516\n",
      "Epoch 85/300\n",
      "12886/12886 [==============================] - 3s 212us/step - loss: 1.8549 - accuracy: 0.6897 - f1_m: 0.6901 - precision_m: 0.6913 - recall_m: 0.6890 - val_loss: 1.9081 - val_accuracy: 0.6335 - val_f1_m: 0.6332 - val_precision_m: 0.6341 - val_recall_m: 0.6323\n",
      "Epoch 86/300\n",
      "12886/12886 [==============================] - 3s 216us/step - loss: 1.8602 - accuracy: 0.6835 - f1_m: 0.6837 - precision_m: 0.6849 - recall_m: 0.6826 - val_loss: 1.9151 - val_accuracy: 0.6304 - val_f1_m: 0.6308 - val_precision_m: 0.6318 - val_recall_m: 0.6299\n",
      "Epoch 87/300\n",
      "12886/12886 [==============================] - 3s 210us/step - loss: 1.8616 - accuracy: 0.6823 - f1_m: 0.6817 - precision_m: 0.6833 - recall_m: 0.6802 - val_loss: 1.9005 - val_accuracy: 0.6440 - val_f1_m: 0.6435 - val_precision_m: 0.6445 - val_recall_m: 0.6425\n",
      "Epoch 88/300\n",
      "12886/12886 [==============================] - 3s 207us/step - loss: 1.8523 - accuracy: 0.6904 - f1_m: 0.6907 - precision_m: 0.6922 - recall_m: 0.6893 - val_loss: 2.0161 - val_accuracy: 0.5376 - val_f1_m: 0.5375 - val_precision_m: 0.5405 - val_recall_m: 0.5349\n",
      "Epoch 89/300\n",
      "12886/12886 [==============================] - 3s 213us/step - loss: 1.8500 - accuracy: 0.6946 - f1_m: 0.6950 - precision_m: 0.6965 - recall_m: 0.6935 - val_loss: 1.8812 - val_accuracy: 0.6595 - val_f1_m: 0.6604 - val_precision_m: 0.6613 - val_recall_m: 0.6594\n",
      "Epoch 90/300\n",
      "12886/12886 [==============================] - 3s 209us/step - loss: 1.8543 - accuracy: 0.6890 - f1_m: 0.6898 - precision_m: 0.6920 - recall_m: 0.6878 - val_loss: 1.9736 - val_accuracy: 0.5608 - val_f1_m: 0.5594 - val_precision_m: 0.5623 - val_recall_m: 0.5567\n",
      "Epoch 91/300\n",
      "12886/12886 [==============================] - 3s 215us/step - loss: 1.8547 - accuracy: 0.6882 - f1_m: 0.6885 - precision_m: 0.6902 - recall_m: 0.6868 - val_loss: 1.9479 - val_accuracy: 0.5981 - val_f1_m: 0.5983 - val_precision_m: 0.5998 - val_recall_m: 0.5968\n",
      "Epoch 92/300\n",
      "12886/12886 [==============================] - 3s 204us/step - loss: 1.8538 - accuracy: 0.6900 - f1_m: 0.6905 - precision_m: 0.6920 - recall_m: 0.6890 - val_loss: 1.9159 - val_accuracy: 0.6260 - val_f1_m: 0.6260 - val_precision_m: 0.6271 - val_recall_m: 0.6250\n",
      "Epoch 93/300\n",
      "12886/12886 [==============================] - 3s 208us/step - loss: 1.8531 - accuracy: 0.6914 - f1_m: 0.6916 - precision_m: 0.6928 - recall_m: 0.6904 - val_loss: 1.9241 - val_accuracy: 0.6182 - val_f1_m: 0.6164 - val_precision_m: 0.6187 - val_recall_m: 0.6143\n",
      "Epoch 94/300\n",
      "12886/12886 [==============================] - 3s 207us/step - loss: 1.8484 - accuracy: 0.6963 - f1_m: 0.6965 - precision_m: 0.6980 - recall_m: 0.6952 - val_loss: 1.9164 - val_accuracy: 0.6254 - val_f1_m: 0.6254 - val_precision_m: 0.6268 - val_recall_m: 0.6241\n",
      "Epoch 95/300\n",
      "12886/12886 [==============================] - 3s 208us/step - loss: 1.8576 - accuracy: 0.6856 - f1_m: 0.6859 - precision_m: 0.6874 - recall_m: 0.6845 - val_loss: 1.9224 - val_accuracy: 0.6145 - val_f1_m: 0.6149 - val_precision_m: 0.6172 - val_recall_m: 0.6126\n",
      "Epoch 96/300\n",
      "12886/12886 [==============================] - 3s 206us/step - loss: 1.8496 - accuracy: 0.6949 - f1_m: 0.6949 - precision_m: 0.6958 - recall_m: 0.6939 - val_loss: 1.9824 - val_accuracy: 0.5562 - val_f1_m: 0.5547 - val_precision_m: 0.5560 - val_recall_m: 0.5534\n",
      "Epoch 97/300\n",
      "12886/12886 [==============================] - 3s 209us/step - loss: 1.8496 - accuracy: 0.6934 - f1_m: 0.6936 - precision_m: 0.6950 - recall_m: 0.6922 - val_loss: 1.8866 - val_accuracy: 0.6524 - val_f1_m: 0.6526 - val_precision_m: 0.6541 - val_recall_m: 0.6511\n",
      "Epoch 98/300\n",
      "12886/12886 [==============================] - 3s 210us/step - loss: 1.8524 - accuracy: 0.6916 - f1_m: 0.6919 - precision_m: 0.6930 - recall_m: 0.6907 - val_loss: 1.9424 - val_accuracy: 0.6046 - val_f1_m: 0.6034 - val_precision_m: 0.6052 - val_recall_m: 0.6017\n",
      "Epoch 99/300\n",
      "12886/12886 [==============================] - 3s 210us/step - loss: 1.8515 - accuracy: 0.6915 - f1_m: 0.6913 - precision_m: 0.6918 - recall_m: 0.6908 - val_loss: 2.1193 - val_accuracy: 0.4215 - val_f1_m: 0.4197 - val_precision_m: 0.4213 - val_recall_m: 0.4181\n",
      "Epoch 100/300\n",
      "12886/12886 [==============================] - 3s 226us/step - loss: 1.8556 - accuracy: 0.6881 - f1_m: 0.6885 - precision_m: 0.6895 - recall_m: 0.6875 - val_loss: 1.8917 - val_accuracy: 0.6511 - val_f1_m: 0.6516 - val_precision_m: 0.6526 - val_recall_m: 0.6506\n",
      "Epoch 101/300\n",
      "12886/12886 [==============================] - 3s 224us/step - loss: 1.8551 - accuracy: 0.6878 - f1_m: 0.6881 - precision_m: 0.6894 - recall_m: 0.6868 - val_loss: 1.8962 - val_accuracy: 0.6409 - val_f1_m: 0.6418 - val_precision_m: 0.6436 - val_recall_m: 0.6401\n",
      "Epoch 102/300\n",
      "12886/12886 [==============================] - 3s 226us/step - loss: 1.8523 - accuracy: 0.6908 - f1_m: 0.6905 - precision_m: 0.6919 - recall_m: 0.6893 - val_loss: 2.0557 - val_accuracy: 0.4845 - val_f1_m: 0.4836 - val_precision_m: 0.4862 - val_recall_m: 0.4810\n",
      "Epoch 103/300\n",
      "12886/12886 [==============================] - 3s 219us/step - loss: 1.8507 - accuracy: 0.6930 - f1_m: 0.6929 - precision_m: 0.6939 - recall_m: 0.6919 - val_loss: 1.9524 - val_accuracy: 0.5885 - val_f1_m: 0.5863 - val_precision_m: 0.5901 - val_recall_m: 0.5828\n",
      "Epoch 104/300\n",
      "12886/12886 [==============================] - 3s 232us/step - loss: 1.8468 - accuracy: 0.6969 - f1_m: 0.6970 - precision_m: 0.6985 - recall_m: 0.6955 - val_loss: 1.9554 - val_accuracy: 0.5857 - val_f1_m: 0.5848 - val_precision_m: 0.5856 - val_recall_m: 0.5839\n",
      "Epoch 105/300\n",
      "12886/12886 [==============================] - 3s 218us/step - loss: 1.8503 - accuracy: 0.6942 - f1_m: 0.6944 - precision_m: 0.6958 - recall_m: 0.6930 - val_loss: 2.0429 - val_accuracy: 0.5040 - val_f1_m: 0.5058 - val_precision_m: 0.5082 - val_recall_m: 0.5034\n",
      "Epoch 106/300\n",
      "12886/12886 [==============================] - 3s 219us/step - loss: 1.8536 - accuracy: 0.6891 - f1_m: 0.6891 - precision_m: 0.6906 - recall_m: 0.6876 - val_loss: 1.9829 - val_accuracy: 0.5590 - val_f1_m: 0.5593 - val_precision_m: 0.5606 - val_recall_m: 0.5580\n",
      "Epoch 107/300\n",
      "12886/12886 [==============================] - 3s 210us/step - loss: 1.8533 - accuracy: 0.6908 - f1_m: 0.6910 - precision_m: 0.6924 - recall_m: 0.6897 - val_loss: 1.9116 - val_accuracy: 0.6307 - val_f1_m: 0.6299 - val_precision_m: 0.6307 - val_recall_m: 0.6292\n",
      "Epoch 108/300\n",
      "12886/12886 [==============================] - 3s 214us/step - loss: 1.8548 - accuracy: 0.6883 - f1_m: 0.6888 - precision_m: 0.6899 - recall_m: 0.6877 - val_loss: 1.9461 - val_accuracy: 0.5990 - val_f1_m: 0.5994 - val_precision_m: 0.6002 - val_recall_m: 0.5985\n",
      "Epoch 109/300\n",
      "12886/12886 [==============================] - 3s 214us/step - loss: 1.8527 - accuracy: 0.6913 - f1_m: 0.6910 - precision_m: 0.6922 - recall_m: 0.6898 - val_loss: 1.8710 - val_accuracy: 0.6710 - val_f1_m: 0.6721 - val_precision_m: 0.6732 - val_recall_m: 0.6710\n",
      "Epoch 110/300\n",
      "12886/12886 [==============================] - 3s 211us/step - loss: 1.8515 - accuracy: 0.6913 - f1_m: 0.6917 - precision_m: 0.6933 - recall_m: 0.6902 - val_loss: 1.9169 - val_accuracy: 0.6276 - val_f1_m: 0.6273 - val_precision_m: 0.6283 - val_recall_m: 0.6263\n",
      "Epoch 111/300\n",
      "12886/12886 [==============================] - 3s 211us/step - loss: 1.8501 - accuracy: 0.6939 - f1_m: 0.6941 - precision_m: 0.6955 - recall_m: 0.6927 - val_loss: 1.9217 - val_accuracy: 0.6279 - val_f1_m: 0.6270 - val_precision_m: 0.6282 - val_recall_m: 0.6258\n",
      "Epoch 112/300\n",
      "12886/12886 [==============================] - 3s 216us/step - loss: 1.8471 - accuracy: 0.6984 - f1_m: 0.6984 - precision_m: 0.6996 - recall_m: 0.6973 - val_loss: 1.9236 - val_accuracy: 0.6238 - val_f1_m: 0.6237 - val_precision_m: 0.6260 - val_recall_m: 0.6216\n",
      "Epoch 113/300\n",
      "12886/12886 [==============================] - 3s 212us/step - loss: 1.8507 - accuracy: 0.6924 - f1_m: 0.6925 - precision_m: 0.6939 - recall_m: 0.6910 - val_loss: 1.9353 - val_accuracy: 0.6061 - val_f1_m: 0.6059 - val_precision_m: 0.6071 - val_recall_m: 0.6047\n",
      "Epoch 114/300\n",
      "12886/12886 [==============================] - 3s 215us/step - loss: 1.8486 - accuracy: 0.6950 - f1_m: 0.6954 - precision_m: 0.6967 - recall_m: 0.6943 - val_loss: 1.9268 - val_accuracy: 0.6145 - val_f1_m: 0.6139 - val_precision_m: 0.6165 - val_recall_m: 0.6114\n",
      "Epoch 115/300\n",
      "12886/12886 [==============================] - 3s 218us/step - loss: 1.8524 - accuracy: 0.6905 - f1_m: 0.6912 - precision_m: 0.6928 - recall_m: 0.6897 - val_loss: 1.9257 - val_accuracy: 0.6158 - val_f1_m: 0.6148 - val_precision_m: 0.6172 - val_recall_m: 0.6125\n",
      "Epoch 116/300\n",
      "12886/12886 [==============================] - 3s 212us/step - loss: 1.8506 - accuracy: 0.6928 - f1_m: 0.6932 - precision_m: 0.6949 - recall_m: 0.6916 - val_loss: 1.9306 - val_accuracy: 0.6127 - val_f1_m: 0.6132 - val_precision_m: 0.6157 - val_recall_m: 0.6109\n",
      "Epoch 117/300\n",
      "12886/12886 [==============================] - 3s 242us/step - loss: 1.8478 - accuracy: 0.6966 - f1_m: 0.6970 - precision_m: 0.6987 - recall_m: 0.6953 - val_loss: 2.0193 - val_accuracy: 0.5220 - val_f1_m: 0.5205 - val_precision_m: 0.5232 - val_recall_m: 0.5180\n",
      "Epoch 118/300\n",
      "12886/12886 [==============================] - 3s 219us/step - loss: 1.8509 - accuracy: 0.6926 - f1_m: 0.6928 - precision_m: 0.6941 - recall_m: 0.6916 - val_loss: 1.9421 - val_accuracy: 0.6021 - val_f1_m: 0.6016 - val_precision_m: 0.6033 - val_recall_m: 0.6001\n",
      "Epoch 119/300\n",
      "12886/12886 [==============================] - 3s 213us/step - loss: 1.8536 - accuracy: 0.6901 - f1_m: 0.6904 - precision_m: 0.6919 - recall_m: 0.6888 - val_loss: 1.8820 - val_accuracy: 0.6617 - val_f1_m: 0.6617 - val_precision_m: 0.6627 - val_recall_m: 0.6607\n",
      "Epoch 120/300\n",
      "12886/12886 [==============================] - 3s 209us/step - loss: 1.8479 - accuracy: 0.6953 - f1_m: 0.6952 - precision_m: 0.6965 - recall_m: 0.6939 - val_loss: 1.9420 - val_accuracy: 0.6027 - val_f1_m: 0.6025 - val_precision_m: 0.6038 - val_recall_m: 0.6011\n",
      "Epoch 121/300\n",
      "12886/12886 [==============================] - 3s 211us/step - loss: 1.8455 - accuracy: 0.6987 - f1_m: 0.6992 - precision_m: 0.7003 - recall_m: 0.6982 - val_loss: 1.9134 - val_accuracy: 0.6300 - val_f1_m: 0.6301 - val_precision_m: 0.6307 - val_recall_m: 0.6295\n",
      "Epoch 122/300\n",
      "12886/12886 [==============================] - 3s 203us/step - loss: 1.8477 - accuracy: 0.6955 - f1_m: 0.6955 - precision_m: 0.6966 - recall_m: 0.6945 - val_loss: 1.9171 - val_accuracy: 0.6288 - val_f1_m: 0.6283 - val_precision_m: 0.6301 - val_recall_m: 0.6265\n",
      "Epoch 123/300\n",
      "12886/12886 [==============================] - 3s 208us/step - loss: 1.8468 - accuracy: 0.6973 - f1_m: 0.6976 - precision_m: 0.6988 - recall_m: 0.6964 - val_loss: 1.9214 - val_accuracy: 0.6158 - val_f1_m: 0.6161 - val_precision_m: 0.6170 - val_recall_m: 0.6151\n",
      "Epoch 124/300\n",
      "12886/12886 [==============================] - 3s 201us/step - loss: 1.8492 - accuracy: 0.6936 - f1_m: 0.6937 - precision_m: 0.6950 - recall_m: 0.6925 - val_loss: 1.9189 - val_accuracy: 0.6257 - val_f1_m: 0.6248 - val_precision_m: 0.6257 - val_recall_m: 0.6239\n",
      "Epoch 125/300\n",
      "12886/12886 [==============================] - 3s 202us/step - loss: 1.8466 - accuracy: 0.6977 - f1_m: 0.6977 - precision_m: 0.6991 - recall_m: 0.6964 - val_loss: 1.9263 - val_accuracy: 0.6151 - val_f1_m: 0.6151 - val_precision_m: 0.6160 - val_recall_m: 0.6143\n",
      "Epoch 126/300\n",
      "12886/12886 [==============================] - 3s 204us/step - loss: 1.8485 - accuracy: 0.6950 - f1_m: 0.6951 - precision_m: 0.6966 - recall_m: 0.6936 - val_loss: 1.8799 - val_accuracy: 0.6648 - val_f1_m: 0.6639 - val_precision_m: 0.6652 - val_recall_m: 0.6626\n",
      "Epoch 127/300\n",
      "12886/12886 [==============================] - 3s 210us/step - loss: 1.8526 - accuracy: 0.6911 - f1_m: 0.6908 - precision_m: 0.6919 - recall_m: 0.6896 - val_loss: 2.1095 - val_accuracy: 0.4264 - val_f1_m: 0.4251 - val_precision_m: 0.4266 - val_recall_m: 0.4237\n",
      "Epoch 128/300\n",
      "12886/12886 [==============================] - 3s 199us/step - loss: 1.8454 - accuracy: 0.6985 - f1_m: 0.6987 - precision_m: 0.7002 - recall_m: 0.6972 - val_loss: 1.8973 - val_accuracy: 0.6515 - val_f1_m: 0.6512 - val_precision_m: 0.6535 - val_recall_m: 0.6489\n",
      "Epoch 129/300\n",
      "12886/12886 [==============================] - 3s 209us/step - loss: 1.8469 - accuracy: 0.6971 - f1_m: 0.6970 - precision_m: 0.6986 - recall_m: 0.6955 - val_loss: 2.1747 - val_accuracy: 0.3625 - val_f1_m: 0.3633 - val_precision_m: 0.3657 - val_recall_m: 0.3610\n",
      "Epoch 130/300\n",
      "12886/12886 [==============================] - 3s 203us/step - loss: 1.8582 - accuracy: 0.6851 - f1_m: 0.6854 - precision_m: 0.6863 - recall_m: 0.6845 - val_loss: 1.8868 - val_accuracy: 0.6567 - val_f1_m: 0.6570 - val_precision_m: 0.6584 - val_recall_m: 0.6557\n",
      "Epoch 131/300\n",
      "12886/12886 [==============================] - 3s 248us/step - loss: 1.8481 - accuracy: 0.6957 - f1_m: 0.6957 - precision_m: 0.6967 - recall_m: 0.6947 - val_loss: 1.8784 - val_accuracy: 0.6629 - val_f1_m: 0.6621 - val_precision_m: 0.6640 - val_recall_m: 0.6602\n",
      "Epoch 132/300\n",
      "12886/12886 [==============================] - 3s 205us/step - loss: 1.8467 - accuracy: 0.6971 - f1_m: 0.6973 - precision_m: 0.6985 - recall_m: 0.6961 - val_loss: 2.0094 - val_accuracy: 0.5323 - val_f1_m: 0.5300 - val_precision_m: 0.5332 - val_recall_m: 0.5269\n",
      "Epoch 133/300\n",
      "12886/12886 [==============================] - 3s 204us/step - loss: 1.8528 - accuracy: 0.6908 - f1_m: 0.6911 - precision_m: 0.6921 - recall_m: 0.6901 - val_loss: 1.9233 - val_accuracy: 0.6210 - val_f1_m: 0.6221 - val_precision_m: 0.6253 - val_recall_m: 0.6189\n",
      "Epoch 134/300\n",
      "12886/12886 [==============================] - 3s 207us/step - loss: 1.8494 - accuracy: 0.6945 - f1_m: 0.6946 - precision_m: 0.6956 - recall_m: 0.6936 - val_loss: 1.8994 - val_accuracy: 0.6434 - val_f1_m: 0.6417 - val_precision_m: 0.6433 - val_recall_m: 0.6402\n",
      "Epoch 135/300\n",
      "12886/12886 [==============================] - 3s 210us/step - loss: 1.8456 - accuracy: 0.6976 - f1_m: 0.6976 - precision_m: 0.6987 - recall_m: 0.6965 - val_loss: 1.9489 - val_accuracy: 0.5947 - val_f1_m: 0.5951 - val_precision_m: 0.5962 - val_recall_m: 0.5941\n",
      "Epoch 136/300\n",
      "12886/12886 [==============================] - 3s 208us/step - loss: 1.8499 - accuracy: 0.6942 - f1_m: 0.6942 - precision_m: 0.6958 - recall_m: 0.6927 - val_loss: 1.9060 - val_accuracy: 0.6350 - val_f1_m: 0.6344 - val_precision_m: 0.6359 - val_recall_m: 0.6330\n",
      "Epoch 137/300\n",
      "12886/12886 [==============================] - 3s 208us/step - loss: 1.8505 - accuracy: 0.6938 - f1_m: 0.6940 - precision_m: 0.6950 - recall_m: 0.6930 - val_loss: 1.9020 - val_accuracy: 0.6338 - val_f1_m: 0.6345 - val_precision_m: 0.6361 - val_recall_m: 0.6330\n",
      "Epoch 138/300\n",
      "12886/12886 [==============================] - 3s 208us/step - loss: 1.8457 - accuracy: 0.6985 - f1_m: 0.6984 - precision_m: 0.6996 - recall_m: 0.6972 - val_loss: 1.9731 - val_accuracy: 0.5723 - val_f1_m: 0.5701 - val_precision_m: 0.5739 - val_recall_m: 0.5667\n",
      "Epoch 139/300\n",
      "12886/12886 [==============================] - 3s 204us/step - loss: 1.8501 - accuracy: 0.6946 - f1_m: 0.6948 - precision_m: 0.6960 - recall_m: 0.6936 - val_loss: 1.9646 - val_accuracy: 0.5798 - val_f1_m: 0.5785 - val_precision_m: 0.5808 - val_recall_m: 0.5763\n",
      "Epoch 140/300\n",
      "12886/12886 [==============================] - 3s 206us/step - loss: 1.8407 - accuracy: 0.7036 - f1_m: 0.7032 - precision_m: 0.7046 - recall_m: 0.7018 - val_loss: 1.9589 - val_accuracy: 0.5791 - val_f1_m: 0.5786 - val_precision_m: 0.5812 - val_recall_m: 0.5760\n",
      "Epoch 141/300\n",
      "12886/12886 [==============================] - 3s 205us/step - loss: 1.8494 - accuracy: 0.6947 - f1_m: 0.6948 - precision_m: 0.6960 - recall_m: 0.6937 - val_loss: 1.8979 - val_accuracy: 0.6418 - val_f1_m: 0.6423 - val_precision_m: 0.6434 - val_recall_m: 0.6412\n",
      "Epoch 142/300\n",
      "12886/12886 [==============================] - 3s 207us/step - loss: 1.8460 - accuracy: 0.6971 - f1_m: 0.6972 - precision_m: 0.6984 - recall_m: 0.6961 - val_loss: 1.9534 - val_accuracy: 0.5916 - val_f1_m: 0.5931 - val_precision_m: 0.5955 - val_recall_m: 0.5908\n",
      "Epoch 143/300\n",
      "12886/12886 [==============================] - 3s 203us/step - loss: 1.8453 - accuracy: 0.6980 - f1_m: 0.6980 - precision_m: 0.6993 - recall_m: 0.6968 - val_loss: 1.9433 - val_accuracy: 0.5971 - val_f1_m: 0.5964 - val_precision_m: 0.5978 - val_recall_m: 0.5950\n",
      "Epoch 144/300\n",
      "12886/12886 [==============================] - 3s 214us/step - loss: 1.8451 - accuracy: 0.6990 - f1_m: 0.6994 - precision_m: 0.7011 - recall_m: 0.6977 - val_loss: 2.0128 - val_accuracy: 0.5282 - val_f1_m: 0.5279 - val_precision_m: 0.5288 - val_recall_m: 0.5270\n",
      "Epoch 145/300\n",
      "12886/12886 [==============================] - 3s 206us/step - loss: 1.8424 - accuracy: 0.7010 - f1_m: 0.7014 - precision_m: 0.7025 - recall_m: 0.7003 - val_loss: 1.9987 - val_accuracy: 0.5462 - val_f1_m: 0.5464 - val_precision_m: 0.5482 - val_recall_m: 0.5446\n",
      "Epoch 146/300\n",
      "12886/12886 [==============================] - 3s 204us/step - loss: 1.8449 - accuracy: 0.6978 - f1_m: 0.6981 - precision_m: 0.6991 - recall_m: 0.6972 - val_loss: 1.8939 - val_accuracy: 0.6434 - val_f1_m: 0.6428 - val_precision_m: 0.6441 - val_recall_m: 0.6415\n",
      "Epoch 147/300\n",
      "12886/12886 [==============================] - 3s 203us/step - loss: 1.8466 - accuracy: 0.6965 - f1_m: 0.6967 - precision_m: 0.6978 - recall_m: 0.6956 - val_loss: 1.9384 - val_accuracy: 0.6006 - val_f1_m: 0.5997 - val_precision_m: 0.6004 - val_recall_m: 0.5990\n",
      "Epoch 148/300\n",
      "12886/12886 [==============================] - 3s 210us/step - loss: 1.8485 - accuracy: 0.6950 - f1_m: 0.6951 - precision_m: 0.6963 - recall_m: 0.6940 - val_loss: 1.8988 - val_accuracy: 0.6446 - val_f1_m: 0.6454 - val_precision_m: 0.6462 - val_recall_m: 0.6446\n",
      "Epoch 149/300\n",
      "12886/12886 [==============================] - 3s 211us/step - loss: 1.8435 - accuracy: 0.7009 - f1_m: 0.7006 - precision_m: 0.7016 - recall_m: 0.6995 - val_loss: 1.8914 - val_accuracy: 0.6502 - val_f1_m: 0.6499 - val_precision_m: 0.6512 - val_recall_m: 0.6487\n",
      "Epoch 150/300\n",
      "12886/12886 [==============================] - 3s 208us/step - loss: 1.8404 - accuracy: 0.7034 - f1_m: 0.7039 - precision_m: 0.7053 - recall_m: 0.7026 - val_loss: 1.9729 - val_accuracy: 0.5692 - val_f1_m: 0.5689 - val_precision_m: 0.5698 - val_recall_m: 0.5681\n",
      "Epoch 151/300\n",
      "12886/12886 [==============================] - 3s 214us/step - loss: 1.8468 - accuracy: 0.6954 - f1_m: 0.6957 - precision_m: 0.6969 - recall_m: 0.6946 - val_loss: 1.9663 - val_accuracy: 0.5711 - val_f1_m: 0.5714 - val_precision_m: 0.5724 - val_recall_m: 0.5704\n",
      "Epoch 152/300\n",
      "12886/12886 [==============================] - 3s 220us/step - loss: 1.8435 - accuracy: 0.7017 - f1_m: 0.7021 - precision_m: 0.7033 - recall_m: 0.7010 - val_loss: 1.9322 - val_accuracy: 0.6089 - val_f1_m: 0.6084 - val_precision_m: 0.6090 - val_recall_m: 0.6078\n",
      "Epoch 153/300\n",
      "12886/12886 [==============================] - 3s 217us/step - loss: 1.8499 - accuracy: 0.6924 - f1_m: 0.6928 - precision_m: 0.6942 - recall_m: 0.6914 - val_loss: 2.0337 - val_accuracy: 0.5065 - val_f1_m: 0.5063 - val_precision_m: 0.5078 - val_recall_m: 0.5049\n",
      "Epoch 154/300\n",
      "12886/12886 [==============================] - 3s 214us/step - loss: 1.8508 - accuracy: 0.6931 - f1_m: 0.6930 - precision_m: 0.6941 - recall_m: 0.6919 - val_loss: 1.9131 - val_accuracy: 0.6341 - val_f1_m: 0.6337 - val_precision_m: 0.6358 - val_recall_m: 0.6316\n",
      "Epoch 155/300\n",
      "12886/12886 [==============================] - 3s 207us/step - loss: 1.8440 - accuracy: 0.7009 - f1_m: 0.7010 - precision_m: 0.7020 - recall_m: 0.6999 - val_loss: 1.8780 - val_accuracy: 0.6595 - val_f1_m: 0.6591 - val_precision_m: 0.6597 - val_recall_m: 0.6586\n",
      "Epoch 156/300\n",
      "12886/12886 [==============================] - 3s 211us/step - loss: 1.8442 - accuracy: 0.6991 - f1_m: 0.6987 - precision_m: 0.7000 - recall_m: 0.6975 - val_loss: 1.8952 - val_accuracy: 0.6462 - val_f1_m: 0.6465 - val_precision_m: 0.6479 - val_recall_m: 0.6452\n",
      "Epoch 157/300\n",
      "12886/12886 [==============================] - 3s 211us/step - loss: 1.8411 - accuracy: 0.7018 - f1_m: 0.7021 - precision_m: 0.7032 - recall_m: 0.7010 - val_loss: 1.8994 - val_accuracy: 0.6403 - val_f1_m: 0.6399 - val_precision_m: 0.6405 - val_recall_m: 0.6394\n",
      "Epoch 158/300\n",
      "12886/12886 [==============================] - 3s 208us/step - loss: 1.8452 - accuracy: 0.6989 - f1_m: 0.6991 - precision_m: 0.7003 - recall_m: 0.6979 - val_loss: 1.8955 - val_accuracy: 0.6474 - val_f1_m: 0.6473 - val_precision_m: 0.6476 - val_recall_m: 0.6469\n",
      "Epoch 159/300\n",
      "12886/12886 [==============================] - 3s 203us/step - loss: 1.8409 - accuracy: 0.7027 - f1_m: 0.7027 - precision_m: 0.7040 - recall_m: 0.7016 - val_loss: 2.0598 - val_accuracy: 0.4817 - val_f1_m: 0.4788 - val_precision_m: 0.4825 - val_recall_m: 0.4754\n",
      "Epoch 160/300\n",
      "12886/12886 [==============================] - 3s 205us/step - loss: 1.8379 - accuracy: 0.7067 - f1_m: 0.7067 - precision_m: 0.7078 - recall_m: 0.7056 - val_loss: 1.9344 - val_accuracy: 0.6105 - val_f1_m: 0.6095 - val_precision_m: 0.6099 - val_recall_m: 0.6091\n",
      "Epoch 161/300\n",
      "12886/12886 [==============================] - 3s 205us/step - loss: 1.8531 - accuracy: 0.6898 - f1_m: 0.6898 - precision_m: 0.6910 - recall_m: 0.6887 - val_loss: 1.8882 - val_accuracy: 0.6555 - val_f1_m: 0.6551 - val_precision_m: 0.6560 - val_recall_m: 0.6543\n",
      "Epoch 162/300\n",
      "12886/12886 [==============================] - 3s 206us/step - loss: 1.8512 - accuracy: 0.6937 - f1_m: 0.6938 - precision_m: 0.6946 - recall_m: 0.6929 - val_loss: 1.9350 - val_accuracy: 0.6096 - val_f1_m: 0.6093 - val_precision_m: 0.6102 - val_recall_m: 0.6084\n",
      "Epoch 163/300\n",
      "12886/12886 [==============================] - 3s 204us/step - loss: 1.8396 - accuracy: 0.7040 - f1_m: 0.7039 - precision_m: 0.7048 - recall_m: 0.7030 - val_loss: 1.8925 - val_accuracy: 0.6499 - val_f1_m: 0.6499 - val_precision_m: 0.6503 - val_recall_m: 0.6494\n",
      "Epoch 164/300\n",
      "12886/12886 [==============================] - 3s 209us/step - loss: 1.8498 - accuracy: 0.6944 - f1_m: 0.6944 - precision_m: 0.6956 - recall_m: 0.6932 - val_loss: 1.9030 - val_accuracy: 0.6406 - val_f1_m: 0.6406 - val_precision_m: 0.6414 - val_recall_m: 0.6398\n",
      "Epoch 165/300\n",
      "12886/12886 [==============================] - 3s 217us/step - loss: 1.8471 - accuracy: 0.6966 - f1_m: 0.6970 - precision_m: 0.6982 - recall_m: 0.6959 - val_loss: 2.2498 - val_accuracy: 0.2908 - val_f1_m: 0.2895 - val_precision_m: 0.2897 - val_recall_m: 0.2893\n",
      "Epoch 166/300\n",
      "12886/12886 [==============================] - 3s 209us/step - loss: 1.8417 - accuracy: 0.7014 - f1_m: 0.7013 - precision_m: 0.7025 - recall_m: 0.7002 - val_loss: 1.9008 - val_accuracy: 0.6471 - val_f1_m: 0.6461 - val_precision_m: 0.6480 - val_recall_m: 0.6443\n",
      "Epoch 167/300\n",
      "12886/12886 [==============================] - 3s 203us/step - loss: 1.8407 - accuracy: 0.7025 - f1_m: 0.7028 - precision_m: 0.7037 - recall_m: 0.7020 - val_loss: 1.8975 - val_accuracy: 0.6443 - val_f1_m: 0.6449 - val_precision_m: 0.6461 - val_recall_m: 0.6437\n",
      "Epoch 168/300\n",
      "12886/12886 [==============================] - 3s 210us/step - loss: 1.8454 - accuracy: 0.6980 - f1_m: 0.6981 - precision_m: 0.6990 - recall_m: 0.6971 - val_loss: 1.9005 - val_accuracy: 0.6437 - val_f1_m: 0.6426 - val_precision_m: 0.6444 - val_recall_m: 0.6409\n",
      "Epoch 169/300\n",
      "12886/12886 [==============================] - 3s 205us/step - loss: 1.8482 - accuracy: 0.6950 - f1_m: 0.6950 - precision_m: 0.6963 - recall_m: 0.6937 - val_loss: 1.8891 - val_accuracy: 0.6549 - val_f1_m: 0.6551 - val_precision_m: 0.6561 - val_recall_m: 0.6542\n",
      "Epoch 170/300\n",
      "12886/12886 [==============================] - 3s 209us/step - loss: 1.8416 - accuracy: 0.7011 - f1_m: 0.7011 - precision_m: 0.7019 - recall_m: 0.7003 - val_loss: 1.8904 - val_accuracy: 0.6505 - val_f1_m: 0.6507 - val_precision_m: 0.6526 - val_recall_m: 0.6491\n",
      "Epoch 171/300\n",
      "12886/12886 [==============================] - 3s 209us/step - loss: 1.8429 - accuracy: 0.6997 - f1_m: 0.7000 - precision_m: 0.7012 - recall_m: 0.6988 - val_loss: 1.9414 - val_accuracy: 0.6040 - val_f1_m: 0.6045 - val_precision_m: 0.6063 - val_recall_m: 0.6028\n",
      "Epoch 172/300\n",
      "12886/12886 [==============================] - 3s 207us/step - loss: 1.8462 - accuracy: 0.6977 - f1_m: 0.6981 - precision_m: 0.6991 - recall_m: 0.6971 - val_loss: 1.8939 - val_accuracy: 0.6459 - val_f1_m: 0.6463 - val_precision_m: 0.6466 - val_recall_m: 0.6461\n",
      "Epoch 173/300\n",
      "12886/12886 [==============================] - 3s 213us/step - loss: 1.8390 - accuracy: 0.7054 - f1_m: 0.7052 - precision_m: 0.7063 - recall_m: 0.7042 - val_loss: 1.9465 - val_accuracy: 0.5928 - val_f1_m: 0.5928 - val_precision_m: 0.5958 - val_recall_m: 0.5900\n",
      "Epoch 174/300\n",
      "12886/12886 [==============================] - 3s 210us/step - loss: 1.8419 - accuracy: 0.7025 - f1_m: 0.7028 - precision_m: 0.7039 - recall_m: 0.7017 - val_loss: 1.8652 - val_accuracy: 0.6757 - val_f1_m: 0.6759 - val_precision_m: 0.6769 - val_recall_m: 0.6749\n",
      "Epoch 175/300\n",
      "12886/12886 [==============================] - 3s 210us/step - loss: 1.8435 - accuracy: 0.6993 - f1_m: 0.6995 - precision_m: 0.7007 - recall_m: 0.6983 - val_loss: 1.9004 - val_accuracy: 0.6359 - val_f1_m: 0.6352 - val_precision_m: 0.6372 - val_recall_m: 0.6332\n",
      "Epoch 176/300\n",
      "12886/12886 [==============================] - 3s 205us/step - loss: 1.8485 - accuracy: 0.6942 - f1_m: 0.6946 - precision_m: 0.6955 - recall_m: 0.6938 - val_loss: 1.8971 - val_accuracy: 0.6446 - val_f1_m: 0.6452 - val_precision_m: 0.6459 - val_recall_m: 0.6445\n",
      "Epoch 177/300\n",
      "12886/12886 [==============================] - 3s 225us/step - loss: 1.8458 - accuracy: 0.6969 - f1_m: 0.6970 - precision_m: 0.6981 - recall_m: 0.6958 - val_loss: 1.9128 - val_accuracy: 0.6325 - val_f1_m: 0.6322 - val_precision_m: 0.6336 - val_recall_m: 0.6309\n",
      "Epoch 178/300\n",
      "12886/12886 [==============================] - 3s 204us/step - loss: 1.8509 - accuracy: 0.6921 - f1_m: 0.6921 - precision_m: 0.6932 - recall_m: 0.6909 - val_loss: 2.0108 - val_accuracy: 0.5317 - val_f1_m: 0.5300 - val_precision_m: 0.5320 - val_recall_m: 0.5280\n",
      "Epoch 179/300\n",
      "12886/12886 [==============================] - 3s 211us/step - loss: 1.8417 - accuracy: 0.7011 - f1_m: 0.7010 - precision_m: 0.7021 - recall_m: 0.6999 - val_loss: 1.9349 - val_accuracy: 0.6092 - val_f1_m: 0.6071 - val_precision_m: 0.6094 - val_recall_m: 0.6051\n",
      "Epoch 180/300\n",
      "12886/12886 [==============================] - 3s 212us/step - loss: 1.8427 - accuracy: 0.7001 - f1_m: 0.7003 - precision_m: 0.7013 - recall_m: 0.6993 - val_loss: 2.0160 - val_accuracy: 0.5264 - val_f1_m: 0.5260 - val_precision_m: 0.5267 - val_recall_m: 0.5252\n",
      "Epoch 181/300\n",
      "12886/12886 [==============================] - 3s 218us/step - loss: 1.8379 - accuracy: 0.7058 - f1_m: 0.7059 - precision_m: 0.7071 - recall_m: 0.7048 - val_loss: 2.2539 - val_accuracy: 0.2812 - val_f1_m: 0.2803 - val_precision_m: 0.2810 - val_recall_m: 0.2797\n",
      "Epoch 182/300\n",
      "12886/12886 [==============================] - 3s 208us/step - loss: 1.8438 - accuracy: 0.7010 - f1_m: 0.7010 - precision_m: 0.7016 - recall_m: 0.7004 - val_loss: 1.9976 - val_accuracy: 0.5419 - val_f1_m: 0.5414 - val_precision_m: 0.5423 - val_recall_m: 0.5406\n",
      "Epoch 183/300\n",
      "12886/12886 [==============================] - 3s 207us/step - loss: 1.8393 - accuracy: 0.7034 - f1_m: 0.7037 - precision_m: 0.7048 - recall_m: 0.7025 - val_loss: 1.9489 - val_accuracy: 0.5916 - val_f1_m: 0.5921 - val_precision_m: 0.5933 - val_recall_m: 0.5910\n",
      "Epoch 184/300\n",
      "12886/12886 [==============================] - 3s 208us/step - loss: 1.8418 - accuracy: 0.7003 - f1_m: 0.7008 - precision_m: 0.7019 - recall_m: 0.6997 - val_loss: 2.0778 - val_accuracy: 0.4606 - val_f1_m: 0.4597 - val_precision_m: 0.4613 - val_recall_m: 0.4581\n",
      "Epoch 185/300\n",
      "12886/12886 [==============================] - 3s 219us/step - loss: 1.8404 - accuracy: 0.7029 - f1_m: 0.7029 - precision_m: 0.7036 - recall_m: 0.7022 - val_loss: 1.9361 - val_accuracy: 0.6037 - val_f1_m: 0.6025 - val_precision_m: 0.6049 - val_recall_m: 0.6003\n",
      "Epoch 186/300\n",
      "12886/12886 [==============================] - 3s 206us/step - loss: 1.8391 - accuracy: 0.7056 - f1_m: 0.7055 - precision_m: 0.7064 - recall_m: 0.7046 - val_loss: 1.9137 - val_accuracy: 0.6297 - val_f1_m: 0.6309 - val_precision_m: 0.6346 - val_recall_m: 0.6273\n",
      "Epoch 187/300\n",
      "12886/12886 [==============================] - 3s 205us/step - loss: 1.8440 - accuracy: 0.6983 - f1_m: 0.6985 - precision_m: 0.6995 - recall_m: 0.6975 - val_loss: 1.9559 - val_accuracy: 0.5850 - val_f1_m: 0.5855 - val_precision_m: 0.5868 - val_recall_m: 0.5842\n",
      "Epoch 188/300\n",
      "12886/12886 [==============================] - 3s 204us/step - loss: 1.8392 - accuracy: 0.7047 - f1_m: 0.7051 - precision_m: 0.7059 - recall_m: 0.7042 - val_loss: 1.8725 - val_accuracy: 0.6698 - val_f1_m: 0.6693 - val_precision_m: 0.6703 - val_recall_m: 0.6684\n",
      "Epoch 189/300\n",
      "12886/12886 [==============================] - 3s 205us/step - loss: 1.8432 - accuracy: 0.6997 - f1_m: 0.6999 - precision_m: 0.7012 - recall_m: 0.6986 - val_loss: 1.9091 - val_accuracy: 0.6366 - val_f1_m: 0.6361 - val_precision_m: 0.6375 - val_recall_m: 0.6346\n",
      "Epoch 190/300\n",
      "12886/12886 [==============================] - 3s 203us/step - loss: 1.8426 - accuracy: 0.7019 - f1_m: 0.7019 - precision_m: 0.7033 - recall_m: 0.7005 - val_loss: 1.9656 - val_accuracy: 0.5720 - val_f1_m: 0.5716 - val_precision_m: 0.5725 - val_recall_m: 0.5707\n",
      "Epoch 191/300\n",
      "12886/12886 [==============================] - 3s 205us/step - loss: 1.8438 - accuracy: 0.7002 - f1_m: 0.7001 - precision_m: 0.7011 - recall_m: 0.6991 - val_loss: 1.9482 - val_accuracy: 0.5962 - val_f1_m: 0.5948 - val_precision_m: 0.5960 - val_recall_m: 0.5936\n",
      "Epoch 192/300\n",
      "12886/12886 [==============================] - 3s 208us/step - loss: 1.8413 - accuracy: 0.7009 - f1_m: 0.7015 - precision_m: 0.7027 - recall_m: 0.7004 - val_loss: 1.9865 - val_accuracy: 0.5528 - val_f1_m: 0.5521 - val_precision_m: 0.5531 - val_recall_m: 0.5511\n",
      "Epoch 193/300\n",
      "12886/12886 [==============================] - 3s 213us/step - loss: 1.8457 - accuracy: 0.6982 - f1_m: 0.6980 - precision_m: 0.6990 - recall_m: 0.6970 - val_loss: 1.9115 - val_accuracy: 0.6304 - val_f1_m: 0.6307 - val_precision_m: 0.6322 - val_recall_m: 0.6292\n",
      "Epoch 194/300\n",
      "12886/12886 [==============================] - 3s 203us/step - loss: 1.8399 - accuracy: 0.7036 - f1_m: 0.7039 - precision_m: 0.7050 - recall_m: 0.7029 - val_loss: 1.8841 - val_accuracy: 0.6574 - val_f1_m: 0.6575 - val_precision_m: 0.6589 - val_recall_m: 0.6561\n",
      "Epoch 195/300\n",
      "12886/12886 [==============================] - 3s 206us/step - loss: 1.8435 - accuracy: 0.6997 - f1_m: 0.6995 - precision_m: 0.7005 - recall_m: 0.6986 - val_loss: 1.9253 - val_accuracy: 0.6158 - val_f1_m: 0.6156 - val_precision_m: 0.6159 - val_recall_m: 0.6154\n",
      "Epoch 196/300\n",
      "12886/12886 [==============================] - 3s 215us/step - loss: 1.8387 - accuracy: 0.7058 - f1_m: 0.7059 - precision_m: 0.7069 - recall_m: 0.7048 - val_loss: 1.9968 - val_accuracy: 0.5466 - val_f1_m: 0.5453 - val_precision_m: 0.5467 - val_recall_m: 0.5439\n",
      "Epoch 197/300\n",
      "12886/12886 [==============================] - 3s 234us/step - loss: 1.8431 - accuracy: 0.7003 - f1_m: 0.7003 - precision_m: 0.7010 - recall_m: 0.6997 - val_loss: 1.9132 - val_accuracy: 0.6285 - val_f1_m: 0.6272 - val_precision_m: 0.6280 - val_recall_m: 0.6264\n",
      "Epoch 198/300\n",
      "12886/12886 [==============================] - 3s 268us/step - loss: 1.8394 - accuracy: 0.7045 - f1_m: 0.7048 - precision_m: 0.7058 - recall_m: 0.7038 - val_loss: 2.0853 - val_accuracy: 0.4559 - val_f1_m: 0.4554 - val_precision_m: 0.4564 - val_recall_m: 0.4545\n",
      "Epoch 199/300\n",
      "12886/12886 [==============================] - 3s 213us/step - loss: 1.8343 - accuracy: 0.7099 - f1_m: 0.7100 - precision_m: 0.7110 - recall_m: 0.7090 - val_loss: 1.9975 - val_accuracy: 0.5410 - val_f1_m: 0.5403 - val_precision_m: 0.5412 - val_recall_m: 0.5394\n",
      "Epoch 200/300\n",
      "12886/12886 [==============================] - 3s 206us/step - loss: 1.8403 - accuracy: 0.7020 - f1_m: 0.7023 - precision_m: 0.7034 - recall_m: 0.7012 - val_loss: 1.9079 - val_accuracy: 0.6372 - val_f1_m: 0.6361 - val_precision_m: 0.6370 - val_recall_m: 0.6352\n",
      "Epoch 201/300\n",
      "12886/12886 [==============================] - 3s 209us/step - loss: 1.8379 - accuracy: 0.7061 - f1_m: 0.7061 - precision_m: 0.7070 - recall_m: 0.7052 - val_loss: 1.9957 - val_accuracy: 0.5478 - val_f1_m: 0.5467 - val_precision_m: 0.5491 - val_recall_m: 0.5444\n",
      "Epoch 202/300\n",
      "12886/12886 [==============================] - 3s 206us/step - loss: 1.8430 - accuracy: 0.7002 - f1_m: 0.7002 - precision_m: 0.7014 - recall_m: 0.6991 - val_loss: 1.9815 - val_accuracy: 0.5587 - val_f1_m: 0.5578 - val_precision_m: 0.5580 - val_recall_m: 0.5576\n",
      "Epoch 203/300\n",
      "12886/12886 [==============================] - 3s 217us/step - loss: 1.8420 - accuracy: 0.7013 - f1_m: 0.7010 - precision_m: 0.7020 - recall_m: 0.7001 - val_loss: 1.9595 - val_accuracy: 0.5829 - val_f1_m: 0.5810 - val_precision_m: 0.5820 - val_recall_m: 0.5800\n",
      "Epoch 204/300\n",
      "12886/12886 [==============================] - 3s 212us/step - loss: 1.8419 - accuracy: 0.7012 - f1_m: 0.7014 - precision_m: 0.7026 - recall_m: 0.7003 - val_loss: 1.9274 - val_accuracy: 0.6108 - val_f1_m: 0.6109 - val_precision_m: 0.6132 - val_recall_m: 0.6089\n",
      "Epoch 205/300\n",
      "12886/12886 [==============================] - 3s 215us/step - loss: 1.8375 - accuracy: 0.7053 - f1_m: 0.7054 - precision_m: 0.7064 - recall_m: 0.7044 - val_loss: 1.8853 - val_accuracy: 0.6570 - val_f1_m: 0.6562 - val_precision_m: 0.6577 - val_recall_m: 0.6548\n",
      "Epoch 206/300\n",
      "12886/12886 [==============================] - 3s 206us/step - loss: 1.8384 - accuracy: 0.7042 - f1_m: 0.7042 - precision_m: 0.7052 - recall_m: 0.7033 - val_loss: 1.8731 - val_accuracy: 0.6664 - val_f1_m: 0.6665 - val_precision_m: 0.6677 - val_recall_m: 0.6653\n",
      "Epoch 207/300\n",
      "12886/12886 [==============================] - 3s 203us/step - loss: 1.8380 - accuracy: 0.7054 - f1_m: 0.7056 - precision_m: 0.7066 - recall_m: 0.7047 - val_loss: 1.9123 - val_accuracy: 0.6322 - val_f1_m: 0.6316 - val_precision_m: 0.6329 - val_recall_m: 0.6304\n",
      "Epoch 208/300\n",
      "12886/12886 [==============================] - 3s 222us/step - loss: 1.8418 - accuracy: 0.7013 - f1_m: 0.7015 - precision_m: 0.7027 - recall_m: 0.7003 - val_loss: 1.9236 - val_accuracy: 0.6182 - val_f1_m: 0.6177 - val_precision_m: 0.6206 - val_recall_m: 0.6149\n",
      "Epoch 209/300\n",
      "12886/12886 [==============================] - 3s 217us/step - loss: 1.8405 - accuracy: 0.7025 - f1_m: 0.7027 - precision_m: 0.7038 - recall_m: 0.7017 - val_loss: 1.8815 - val_accuracy: 0.6620 - val_f1_m: 0.6619 - val_precision_m: 0.6628 - val_recall_m: 0.6609\n",
      "Epoch 210/300\n",
      "12886/12886 [==============================] - 3s 219us/step - loss: 1.8398 - accuracy: 0.7039 - f1_m: 0.7047 - precision_m: 0.7060 - recall_m: 0.7034 - val_loss: 1.9436 - val_accuracy: 0.6002 - val_f1_m: 0.6011 - val_precision_m: 0.6020 - val_recall_m: 0.6003\n",
      "Epoch 211/300\n",
      "12886/12886 [==============================] - 3s 208us/step - loss: 1.8440 - accuracy: 0.6990 - f1_m: 0.6991 - precision_m: 0.7001 - recall_m: 0.6981 - val_loss: 1.9262 - val_accuracy: 0.6145 - val_f1_m: 0.6137 - val_precision_m: 0.6144 - val_recall_m: 0.6131\n",
      "Epoch 212/300\n",
      "12886/12886 [==============================] - 3s 218us/step - loss: 1.8377 - accuracy: 0.7059 - f1_m: 0.7059 - precision_m: 0.7069 - recall_m: 0.7050 - val_loss: 1.9205 - val_accuracy: 0.6241 - val_f1_m: 0.6227 - val_precision_m: 0.6245 - val_recall_m: 0.6211\n",
      "Epoch 213/300\n",
      "12886/12886 [==============================] - 3s 208us/step - loss: 1.8367 - accuracy: 0.7069 - f1_m: 0.7072 - precision_m: 0.7079 - recall_m: 0.7065 - val_loss: 1.9072 - val_accuracy: 0.6363 - val_f1_m: 0.6363 - val_precision_m: 0.6373 - val_recall_m: 0.6354\n",
      "Epoch 214/300\n",
      "12886/12886 [==============================] - 3s 211us/step - loss: 1.8385 - accuracy: 0.7059 - f1_m: 0.7063 - precision_m: 0.7077 - recall_m: 0.7050 - val_loss: 1.9353 - val_accuracy: 0.6161 - val_f1_m: 0.6152 - val_precision_m: 0.6176 - val_recall_m: 0.6129\n",
      "Epoch 215/300\n",
      "12886/12886 [==============================] - 3s 204us/step - loss: 1.8365 - accuracy: 0.7075 - f1_m: 0.7076 - precision_m: 0.7087 - recall_m: 0.7065 - val_loss: 1.8781 - val_accuracy: 0.6626 - val_f1_m: 0.6633 - val_precision_m: 0.6640 - val_recall_m: 0.6625\n",
      "Epoch 216/300\n",
      "12886/12886 [==============================] - 3s 204us/step - loss: 1.8359 - accuracy: 0.7062 - f1_m: 0.7066 - precision_m: 0.7077 - recall_m: 0.7055 - val_loss: 1.8997 - val_accuracy: 0.6415 - val_f1_m: 0.6412 - val_precision_m: 0.6422 - val_recall_m: 0.6403\n",
      "Epoch 217/300\n",
      "12886/12886 [==============================] - 3s 208us/step - loss: 1.8395 - accuracy: 0.7042 - f1_m: 0.7044 - precision_m: 0.7053 - recall_m: 0.7034 - val_loss: 1.9303 - val_accuracy: 0.6096 - val_f1_m: 0.6100 - val_precision_m: 0.6106 - val_recall_m: 0.6094\n",
      "Epoch 218/300\n",
      "12886/12886 [==============================] - 3s 203us/step - loss: 1.8386 - accuracy: 0.7059 - f1_m: 0.7056 - precision_m: 0.7066 - recall_m: 0.7047 - val_loss: 1.9346 - val_accuracy: 0.6061 - val_f1_m: 0.6062 - val_precision_m: 0.6081 - val_recall_m: 0.6043\n",
      "Epoch 219/300\n",
      "12886/12886 [==============================] - 3s 206us/step - loss: 1.8403 - accuracy: 0.7029 - f1_m: 0.7024 - precision_m: 0.7035 - recall_m: 0.7012 - val_loss: 1.9308 - val_accuracy: 0.6105 - val_f1_m: 0.6122 - val_precision_m: 0.6168 - val_recall_m: 0.6080\n",
      "Epoch 220/300\n",
      "12886/12886 [==============================] - 3s 209us/step - loss: 1.8329 - accuracy: 0.7111 - f1_m: 0.7112 - precision_m: 0.7119 - recall_m: 0.7106 - val_loss: 1.9188 - val_accuracy: 0.6251 - val_f1_m: 0.6253 - val_precision_m: 0.6270 - val_recall_m: 0.6236\n",
      "Epoch 221/300\n",
      "12886/12886 [==============================] - 3s 218us/step - loss: 1.8396 - accuracy: 0.7045 - f1_m: 0.7042 - precision_m: 0.7051 - recall_m: 0.7033 - val_loss: 1.8908 - val_accuracy: 0.6530 - val_f1_m: 0.6528 - val_precision_m: 0.6532 - val_recall_m: 0.6524\n",
      "Epoch 222/300\n",
      "12886/12886 [==============================] - 3s 233us/step - loss: 1.8406 - accuracy: 0.7027 - f1_m: 0.7024 - precision_m: 0.7032 - recall_m: 0.7016 - val_loss: 1.9995 - val_accuracy: 0.5435 - val_f1_m: 0.5428 - val_precision_m: 0.5440 - val_recall_m: 0.5416\n",
      "Epoch 223/300\n",
      "12886/12886 [==============================] - 3s 244us/step - loss: 1.8416 - accuracy: 0.7015 - f1_m: 0.7015 - precision_m: 0.7026 - recall_m: 0.7004 - val_loss: 2.0991 - val_accuracy: 0.4404 - val_f1_m: 0.4385 - val_precision_m: 0.4396 - val_recall_m: 0.4374\n",
      "Epoch 224/300\n",
      "12886/12886 [==============================] - 3s 245us/step - loss: 1.8388 - accuracy: 0.7043 - f1_m: 0.7039 - precision_m: 0.7050 - recall_m: 0.7028 - val_loss: 1.8712 - val_accuracy: 0.6707 - val_f1_m: 0.6709 - val_precision_m: 0.6716 - val_recall_m: 0.6702\n",
      "Epoch 225/300\n",
      "12886/12886 [==============================] - 3s 242us/step - loss: 1.8331 - accuracy: 0.7095 - f1_m: 0.7097 - precision_m: 0.7108 - recall_m: 0.7085 - val_loss: 2.0161 - val_accuracy: 0.5255 - val_f1_m: 0.5253 - val_precision_m: 0.5261 - val_recall_m: 0.5245\n",
      "Epoch 226/300\n",
      "12886/12886 [==============================] - 3s 247us/step - loss: 1.8352 - accuracy: 0.7100 - f1_m: 0.7103 - precision_m: 0.7114 - recall_m: 0.7092 - val_loss: 1.8909 - val_accuracy: 0.6499 - val_f1_m: 0.6506 - val_precision_m: 0.6516 - val_recall_m: 0.6497\n",
      "Epoch 227/300\n",
      "12886/12886 [==============================] - 3s 235us/step - loss: 1.8360 - accuracy: 0.7082 - f1_m: 0.7084 - precision_m: 0.7097 - recall_m: 0.7072 - val_loss: 1.9048 - val_accuracy: 0.6366 - val_f1_m: 0.6365 - val_precision_m: 0.6385 - val_recall_m: 0.6345\n",
      "Epoch 228/300\n",
      "12886/12886 [==============================] - 3s 247us/step - loss: 1.8372 - accuracy: 0.7056 - f1_m: 0.7058 - precision_m: 0.7069 - recall_m: 0.7048 - val_loss: 1.8961 - val_accuracy: 0.6456 - val_f1_m: 0.6461 - val_precision_m: 0.6485 - val_recall_m: 0.6437\n",
      "Epoch 229/300\n",
      "12886/12886 [==============================] - 3s 252us/step - loss: 1.8393 - accuracy: 0.7040 - f1_m: 0.7042 - precision_m: 0.7051 - recall_m: 0.7032 - val_loss: 1.8795 - val_accuracy: 0.6592 - val_f1_m: 0.6598 - val_precision_m: 0.6608 - val_recall_m: 0.6588\n",
      "Epoch 230/300\n",
      "12886/12886 [==============================] - 3s 260us/step - loss: 1.8342 - accuracy: 0.7092 - f1_m: 0.7092 - precision_m: 0.7100 - recall_m: 0.7085 - val_loss: 2.2835 - val_accuracy: 0.2495 - val_f1_m: 0.2482 - val_precision_m: 0.2497 - val_recall_m: 0.2468\n",
      "Epoch 231/300\n",
      "12886/12886 [==============================] - 4s 277us/step - loss: 1.8345 - accuracy: 0.7097 - f1_m: 0.7098 - precision_m: 0.7106 - recall_m: 0.7091 - val_loss: 1.9032 - val_accuracy: 0.6381 - val_f1_m: 0.6376 - val_precision_m: 0.6392 - val_recall_m: 0.6361\n",
      "Epoch 232/300\n",
      "12886/12886 [==============================] - 4s 282us/step - loss: 1.8359 - accuracy: 0.7075 - f1_m: 0.7077 - precision_m: 0.7088 - recall_m: 0.7067 - val_loss: 1.9429 - val_accuracy: 0.5968 - val_f1_m: 0.5971 - val_precision_m: 0.5984 - val_recall_m: 0.5959\n",
      "Epoch 233/300\n",
      "12886/12886 [==============================] - 3s 261us/step - loss: 1.8354 - accuracy: 0.7077 - f1_m: 0.7080 - precision_m: 0.7091 - recall_m: 0.7069 - val_loss: 1.8977 - val_accuracy: 0.6459 - val_f1_m: 0.6464 - val_precision_m: 0.6467 - val_recall_m: 0.6461\n",
      "Epoch 234/300\n",
      "12886/12886 [==============================] - 3s 255us/step - loss: 1.8409 - accuracy: 0.7029 - f1_m: 0.7035 - precision_m: 0.7048 - recall_m: 0.7023 - val_loss: 1.9105 - val_accuracy: 0.6297 - val_f1_m: 0.6305 - val_precision_m: 0.6328 - val_recall_m: 0.6282\n",
      "Epoch 235/300\n",
      "12886/12886 [==============================] - 3s 268us/step - loss: 1.8364 - accuracy: 0.7054 - f1_m: 0.7057 - precision_m: 0.7067 - recall_m: 0.7049 - val_loss: 1.9292 - val_accuracy: 0.6086 - val_f1_m: 0.6083 - val_precision_m: 0.6103 - val_recall_m: 0.6065\n",
      "Epoch 236/300\n",
      "12886/12886 [==============================] - 3s 260us/step - loss: 1.8372 - accuracy: 0.7067 - f1_m: 0.7067 - precision_m: 0.7079 - recall_m: 0.7056 - val_loss: 1.9420 - val_accuracy: 0.6024 - val_f1_m: 0.6018 - val_precision_m: 0.6024 - val_recall_m: 0.6012\n",
      "Epoch 237/300\n",
      "12886/12886 [==============================] - 3s 235us/step - loss: 1.8353 - accuracy: 0.7084 - f1_m: 0.7088 - precision_m: 0.7098 - recall_m: 0.7079 - val_loss: 1.9183 - val_accuracy: 0.6291 - val_f1_m: 0.6296 - val_precision_m: 0.6301 - val_recall_m: 0.6291\n",
      "Epoch 238/300\n",
      "12886/12886 [==============================] - 3s 249us/step - loss: 1.8425 - accuracy: 0.7009 - f1_m: 0.7013 - precision_m: 0.7024 - recall_m: 0.7003 - val_loss: 1.8835 - val_accuracy: 0.6583 - val_f1_m: 0.6589 - val_precision_m: 0.6604 - val_recall_m: 0.6575\n",
      "Epoch 239/300\n",
      "12886/12886 [==============================] - 3s 243us/step - loss: 1.8359 - accuracy: 0.7077 - f1_m: 0.7079 - precision_m: 0.7087 - recall_m: 0.7071 - val_loss: 1.9209 - val_accuracy: 0.6161 - val_f1_m: 0.6151 - val_precision_m: 0.6161 - val_recall_m: 0.6143\n",
      "Epoch 240/300\n",
      "12886/12886 [==============================] - 3s 234us/step - loss: 1.8377 - accuracy: 0.7063 - f1_m: 0.7065 - precision_m: 0.7075 - recall_m: 0.7056 - val_loss: 1.8949 - val_accuracy: 0.6440 - val_f1_m: 0.6443 - val_precision_m: 0.6452 - val_recall_m: 0.6434\n",
      "Epoch 241/300\n",
      "12886/12886 [==============================] - 3s 242us/step - loss: 1.8371 - accuracy: 0.7064 - f1_m: 0.7068 - precision_m: 0.7081 - recall_m: 0.7056 - val_loss: 2.1487 - val_accuracy: 0.3901 - val_f1_m: 0.3891 - val_precision_m: 0.3910 - val_recall_m: 0.3872\n",
      "Epoch 242/300\n",
      "12886/12886 [==============================] - 3s 231us/step - loss: 1.8484 - accuracy: 0.6948 - f1_m: 0.6951 - precision_m: 0.6961 - recall_m: 0.6941 - val_loss: 1.8859 - val_accuracy: 0.6577 - val_f1_m: 0.6576 - val_precision_m: 0.6586 - val_recall_m: 0.6567\n",
      "Epoch 243/300\n",
      "12886/12886 [==============================] - 3s 245us/step - loss: 1.8404 - accuracy: 0.7040 - f1_m: 0.7042 - precision_m: 0.7051 - recall_m: 0.7034 - val_loss: 1.8952 - val_accuracy: 0.6468 - val_f1_m: 0.6465 - val_precision_m: 0.6471 - val_recall_m: 0.6460\n",
      "Epoch 244/300\n",
      "12886/12886 [==============================] - 3s 240us/step - loss: 1.8343 - accuracy: 0.7103 - f1_m: 0.7105 - precision_m: 0.7117 - recall_m: 0.7095 - val_loss: 1.8703 - val_accuracy: 0.6726 - val_f1_m: 0.6721 - val_precision_m: 0.6729 - val_recall_m: 0.6714\n",
      "Epoch 245/300\n",
      "12886/12886 [==============================] - 3s 236us/step - loss: 1.8369 - accuracy: 0.7063 - f1_m: 0.7062 - precision_m: 0.7071 - recall_m: 0.7054 - val_loss: 1.9069 - val_accuracy: 0.6316 - val_f1_m: 0.6328 - val_precision_m: 0.6336 - val_recall_m: 0.6320\n",
      "Epoch 246/300\n",
      "12886/12886 [==============================] - 3s 242us/step - loss: 1.8357 - accuracy: 0.7074 - f1_m: 0.7074 - precision_m: 0.7081 - recall_m: 0.7067 - val_loss: 2.1563 - val_accuracy: 0.3793 - val_f1_m: 0.3792 - val_precision_m: 0.3801 - val_recall_m: 0.3784\n",
      "Epoch 247/300\n",
      "12886/12886 [==============================] - 3s 236us/step - loss: 1.8352 - accuracy: 0.7080 - f1_m: 0.7081 - precision_m: 0.7091 - recall_m: 0.7072 - val_loss: 1.9193 - val_accuracy: 0.6279 - val_f1_m: 0.6281 - val_precision_m: 0.6285 - val_recall_m: 0.6277\n",
      "Epoch 248/300\n",
      "12886/12886 [==============================] - 3s 252us/step - loss: 1.8345 - accuracy: 0.7098 - f1_m: 0.7099 - precision_m: 0.7111 - recall_m: 0.7088 - val_loss: 1.9682 - val_accuracy: 0.5739 - val_f1_m: 0.5738 - val_precision_m: 0.5758 - val_recall_m: 0.5718\n",
      "Epoch 249/300\n",
      "12886/12886 [==============================] - 3s 246us/step - loss: 1.8377 - accuracy: 0.7050 - f1_m: 0.7052 - precision_m: 0.7063 - recall_m: 0.7042 - val_loss: 1.9671 - val_accuracy: 0.5739 - val_f1_m: 0.5741 - val_precision_m: 0.5753 - val_recall_m: 0.5730\n",
      "Epoch 250/300\n",
      "12886/12886 [==============================] - 3s 254us/step - loss: 1.8291 - accuracy: 0.7143 - f1_m: 0.7146 - precision_m: 0.7155 - recall_m: 0.7138 - val_loss: 1.9117 - val_accuracy: 0.6328 - val_f1_m: 0.6321 - val_precision_m: 0.6337 - val_recall_m: 0.6306\n",
      "Epoch 251/300\n",
      "12886/12886 [==============================] - 3s 253us/step - loss: 1.8347 - accuracy: 0.7086 - f1_m: 0.7086 - precision_m: 0.7094 - recall_m: 0.7078 - val_loss: 1.8926 - val_accuracy: 0.6484 - val_f1_m: 0.6483 - val_precision_m: 0.6491 - val_recall_m: 0.6475\n",
      "Epoch 252/300\n",
      "12886/12886 [==============================] - 3s 237us/step - loss: 1.8386 - accuracy: 0.7050 - f1_m: 0.7045 - precision_m: 0.7057 - recall_m: 0.7034 - val_loss: 2.0515 - val_accuracy: 0.4882 - val_f1_m: 0.4881 - val_precision_m: 0.4899 - val_recall_m: 0.4864\n",
      "Epoch 253/300\n",
      "12886/12886 [==============================] - 3s 245us/step - loss: 1.8403 - accuracy: 0.7025 - f1_m: 0.7024 - precision_m: 0.7033 - recall_m: 0.7015 - val_loss: 2.0896 - val_accuracy: 0.4435 - val_f1_m: 0.4424 - val_precision_m: 0.4444 - val_recall_m: 0.4404\n",
      "Epoch 254/300\n",
      "12886/12886 [==============================] - 3s 244us/step - loss: 1.8344 - accuracy: 0.7094 - f1_m: 0.7098 - precision_m: 0.7108 - recall_m: 0.7088 - val_loss: 1.8885 - val_accuracy: 0.6530 - val_f1_m: 0.6529 - val_precision_m: 0.6543 - val_recall_m: 0.6516\n",
      "Epoch 255/300\n",
      "12886/12886 [==============================] - 3s 241us/step - loss: 1.8346 - accuracy: 0.7087 - f1_m: 0.7091 - precision_m: 0.7100 - recall_m: 0.7082 - val_loss: 1.9643 - val_accuracy: 0.5782 - val_f1_m: 0.5788 - val_precision_m: 0.5802 - val_recall_m: 0.5775\n",
      "Epoch 256/300\n",
      "12886/12886 [==============================] - 3s 249us/step - loss: 1.8385 - accuracy: 0.7039 - f1_m: 0.7040 - precision_m: 0.7048 - recall_m: 0.7031 - val_loss: 1.9510 - val_accuracy: 0.5916 - val_f1_m: 0.5902 - val_precision_m: 0.5914 - val_recall_m: 0.5891\n",
      "Epoch 257/300\n",
      "12886/12886 [==============================] - 3s 259us/step - loss: 1.8383 - accuracy: 0.7063 - f1_m: 0.7064 - precision_m: 0.7073 - recall_m: 0.7054 - val_loss: 1.9213 - val_accuracy: 0.6223 - val_f1_m: 0.6215 - val_precision_m: 0.6219 - val_recall_m: 0.6211\n",
      "Epoch 258/300\n",
      "12886/12886 [==============================] - 3s 272us/step - loss: 1.8327 - accuracy: 0.7110 - f1_m: 0.7110 - precision_m: 0.7120 - recall_m: 0.7099 - val_loss: 1.9302 - val_accuracy: 0.6099 - val_f1_m: 0.6097 - val_precision_m: 0.6115 - val_recall_m: 0.6082\n",
      "Epoch 259/300\n",
      "12886/12886 [==============================] - 3s 268us/step - loss: 1.8359 - accuracy: 0.7074 - f1_m: 0.7076 - precision_m: 0.7087 - recall_m: 0.7066 - val_loss: 1.9213 - val_accuracy: 0.6204 - val_f1_m: 0.6199 - val_precision_m: 0.6206 - val_recall_m: 0.6193\n",
      "Epoch 260/300\n",
      "12886/12886 [==============================] - 3s 245us/step - loss: 1.8394 - accuracy: 0.7037 - f1_m: 0.7038 - precision_m: 0.7050 - recall_m: 0.7026 - val_loss: 1.9152 - val_accuracy: 0.6276 - val_f1_m: 0.6269 - val_precision_m: 0.6282 - val_recall_m: 0.6256\n",
      "Epoch 261/300\n",
      "12886/12886 [==============================] - 3s 259us/step - loss: 1.8362 - accuracy: 0.7076 - f1_m: 0.7078 - precision_m: 0.7089 - recall_m: 0.7067 - val_loss: 1.9441 - val_accuracy: 0.6002 - val_f1_m: 0.6011 - val_precision_m: 0.6027 - val_recall_m: 0.5995\n",
      "Epoch 262/300\n",
      "12886/12886 [==============================] - 3s 254us/step - loss: 1.8373 - accuracy: 0.7071 - f1_m: 0.7074 - precision_m: 0.7085 - recall_m: 0.7064 - val_loss: 1.9122 - val_accuracy: 0.6310 - val_f1_m: 0.6309 - val_precision_m: 0.6316 - val_recall_m: 0.6303\n",
      "Epoch 263/300\n",
      "12886/12886 [==============================] - 3s 239us/step - loss: 1.8397 - accuracy: 0.7044 - f1_m: 0.7046 - precision_m: 0.7058 - recall_m: 0.7034 - val_loss: 1.9013 - val_accuracy: 0.6397 - val_f1_m: 0.6386 - val_precision_m: 0.6400 - val_recall_m: 0.6372\n",
      "Epoch 264/300\n",
      "12886/12886 [==============================] - 4s 276us/step - loss: 1.8341 - accuracy: 0.7096 - f1_m: 0.7101 - precision_m: 0.7114 - recall_m: 0.7088 - val_loss: 1.9309 - val_accuracy: 0.6120 - val_f1_m: 0.6118 - val_precision_m: 0.6122 - val_recall_m: 0.6114\n",
      "Epoch 265/300\n",
      "12886/12886 [==============================] - 5s 358us/step - loss: 1.8348 - accuracy: 0.7099 - f1_m: 0.7102 - precision_m: 0.7112 - recall_m: 0.7093 - val_loss: 1.8718 - val_accuracy: 0.6698 - val_f1_m: 0.6696 - val_precision_m: 0.6702 - val_recall_m: 0.6690\n",
      "Epoch 266/300\n",
      "12886/12886 [==============================] - 3s 251us/step - loss: 1.8335 - accuracy: 0.7095 - f1_m: 0.7098 - precision_m: 0.7106 - recall_m: 0.7090 - val_loss: 1.9304 - val_accuracy: 0.6111 - val_f1_m: 0.6113 - val_precision_m: 0.6121 - val_recall_m: 0.6106\n",
      "Epoch 267/300\n",
      "12886/12886 [==============================] - 3s 252us/step - loss: 1.8402 - accuracy: 0.7022 - f1_m: 0.7023 - precision_m: 0.7032 - recall_m: 0.7014 - val_loss: 2.0080 - val_accuracy: 0.5320 - val_f1_m: 0.5327 - val_precision_m: 0.5353 - val_recall_m: 0.5303\n",
      "Epoch 268/300\n",
      "12886/12886 [==============================] - 3s 268us/step - loss: 1.8360 - accuracy: 0.7067 - f1_m: 0.7067 - precision_m: 0.7074 - recall_m: 0.7061 - val_loss: 1.9223 - val_accuracy: 0.6192 - val_f1_m: 0.6195 - val_precision_m: 0.6203 - val_recall_m: 0.6186\n",
      "Epoch 269/300\n",
      "12886/12886 [==============================] - 3s 256us/step - loss: 1.8328 - accuracy: 0.7104 - f1_m: 0.7104 - precision_m: 0.7112 - recall_m: 0.7095 - val_loss: 1.8682 - val_accuracy: 0.6754 - val_f1_m: 0.6755 - val_precision_m: 0.6770 - val_recall_m: 0.6741\n",
      "Epoch 270/300\n",
      "12886/12886 [==============================] - 3s 249us/step - loss: 1.8449 - accuracy: 0.6991 - f1_m: 0.6989 - precision_m: 0.6997 - recall_m: 0.6981 - val_loss: 1.8856 - val_accuracy: 0.6543 - val_f1_m: 0.6543 - val_precision_m: 0.6549 - val_recall_m: 0.6537\n",
      "Epoch 271/300\n",
      "12886/12886 [==============================] - 3s 234us/step - loss: 1.8362 - accuracy: 0.7070 - f1_m: 0.7068 - precision_m: 0.7082 - recall_m: 0.7054 - val_loss: 1.9708 - val_accuracy: 0.5723 - val_f1_m: 0.5722 - val_precision_m: 0.5735 - val_recall_m: 0.5710\n",
      "Epoch 272/300\n",
      "12886/12886 [==============================] - 3s 247us/step - loss: 1.8325 - accuracy: 0.7105 - f1_m: 0.7103 - precision_m: 0.7112 - recall_m: 0.7093 - val_loss: 1.8857 - val_accuracy: 0.6561 - val_f1_m: 0.6559 - val_precision_m: 0.6565 - val_recall_m: 0.6553\n",
      "Epoch 273/300\n",
      "12886/12886 [==============================] - 3s 240us/step - loss: 1.8336 - accuracy: 0.7098 - f1_m: 0.7097 - precision_m: 0.7106 - recall_m: 0.7088 - val_loss: 2.1281 - val_accuracy: 0.4038 - val_f1_m: 0.4009 - val_precision_m: 0.4041 - val_recall_m: 0.3978\n",
      "Epoch 274/300\n",
      "12886/12886 [==============================] - 3s 239us/step - loss: 1.8286 - accuracy: 0.7153 - f1_m: 0.7152 - precision_m: 0.7161 - recall_m: 0.7143 - val_loss: 1.8654 - val_accuracy: 0.6797 - val_f1_m: 0.6778 - val_precision_m: 0.6789 - val_recall_m: 0.6768\n",
      "Epoch 275/300\n",
      "12886/12886 [==============================] - 3s 250us/step - loss: 1.8394 - accuracy: 0.7036 - f1_m: 0.7039 - precision_m: 0.7049 - recall_m: 0.7030 - val_loss: 1.8689 - val_accuracy: 0.6778 - val_f1_m: 0.6778 - val_precision_m: 0.6795 - val_recall_m: 0.6762\n",
      "Epoch 276/300\n",
      "12886/12886 [==============================] - 3s 216us/step - loss: 1.8333 - accuracy: 0.7094 - f1_m: 0.7096 - precision_m: 0.7105 - recall_m: 0.7086 - val_loss: 1.8610 - val_accuracy: 0.6809 - val_f1_m: 0.6815 - val_precision_m: 0.6826 - val_recall_m: 0.6805\n",
      "Epoch 277/300\n",
      "12886/12886 [==============================] - 3s 219us/step - loss: 1.8322 - accuracy: 0.7110 - f1_m: 0.7110 - precision_m: 0.7120 - recall_m: 0.7100 - val_loss: 1.9302 - val_accuracy: 0.6145 - val_f1_m: 0.6136 - val_precision_m: 0.6144 - val_recall_m: 0.6128\n",
      "Epoch 278/300\n",
      "12886/12886 [==============================] - 3s 200us/step - loss: 1.8355 - accuracy: 0.7077 - f1_m: 0.7079 - precision_m: 0.7088 - recall_m: 0.7070 - val_loss: 1.8830 - val_accuracy: 0.6595 - val_f1_m: 0.6593 - val_precision_m: 0.6600 - val_recall_m: 0.6587\n",
      "Epoch 279/300\n",
      "12886/12886 [==============================] - 3s 207us/step - loss: 1.8341 - accuracy: 0.7084 - f1_m: 0.7088 - precision_m: 0.7098 - recall_m: 0.7078 - val_loss: 1.9142 - val_accuracy: 0.6229 - val_f1_m: 0.6225 - val_precision_m: 0.6242 - val_recall_m: 0.6209\n",
      "Epoch 280/300\n",
      "12886/12886 [==============================] - 3s 200us/step - loss: 1.8363 - accuracy: 0.7066 - f1_m: 0.7064 - precision_m: 0.7071 - recall_m: 0.7057 - val_loss: 1.9730 - val_accuracy: 0.5667 - val_f1_m: 0.5661 - val_precision_m: 0.5671 - val_recall_m: 0.5651\n",
      "Epoch 281/300\n",
      "12886/12886 [==============================] - 3s 213us/step - loss: 1.8312 - accuracy: 0.7119 - f1_m: 0.7121 - precision_m: 0.7132 - recall_m: 0.7111 - val_loss: 1.9648 - val_accuracy: 0.5745 - val_f1_m: 0.5737 - val_precision_m: 0.5748 - val_recall_m: 0.5726\n",
      "Epoch 282/300\n",
      "12886/12886 [==============================] - 3s 207us/step - loss: 1.8363 - accuracy: 0.7071 - f1_m: 0.7075 - precision_m: 0.7085 - recall_m: 0.7064 - val_loss: 1.9237 - val_accuracy: 0.6164 - val_f1_m: 0.6164 - val_precision_m: 0.6176 - val_recall_m: 0.6151\n",
      "Epoch 283/300\n",
      "12886/12886 [==============================] - 3s 262us/step - loss: 1.8342 - accuracy: 0.7086 - f1_m: 0.7087 - precision_m: 0.7097 - recall_m: 0.7077 - val_loss: 2.0839 - val_accuracy: 0.4612 - val_f1_m: 0.4617 - val_precision_m: 0.4681 - val_recall_m: 0.4560\n",
      "Epoch 284/300\n",
      "12886/12886 [==============================] - 3s 246us/step - loss: 1.8320 - accuracy: 0.7113 - f1_m: 0.7116 - precision_m: 0.7125 - recall_m: 0.7106 - val_loss: 1.8770 - val_accuracy: 0.6667 - val_f1_m: 0.6661 - val_precision_m: 0.6671 - val_recall_m: 0.6651\n",
      "Epoch 285/300\n",
      "12886/12886 [==============================] - 3s 237us/step - loss: 1.8344 - accuracy: 0.7090 - f1_m: 0.7092 - precision_m: 0.7099 - recall_m: 0.7085 - val_loss: 1.8593 - val_accuracy: 0.6809 - val_f1_m: 0.6799 - val_precision_m: 0.6822 - val_recall_m: 0.6777\n",
      "Epoch 286/300\n",
      "12886/12886 [==============================] - 3s 227us/step - loss: 1.8329 - accuracy: 0.7106 - f1_m: 0.7106 - precision_m: 0.7114 - recall_m: 0.7099 - val_loss: 2.1730 - val_accuracy: 0.3672 - val_f1_m: 0.3646 - val_precision_m: 0.3654 - val_recall_m: 0.3638\n",
      "Epoch 287/300\n",
      "12886/12886 [==============================] - 3s 239us/step - loss: 1.8323 - accuracy: 0.7106 - f1_m: 0.7108 - precision_m: 0.7120 - recall_m: 0.7097 - val_loss: 1.9161 - val_accuracy: 0.6254 - val_f1_m: 0.6252 - val_precision_m: 0.6264 - val_recall_m: 0.6241\n",
      "Epoch 288/300\n",
      "12886/12886 [==============================] - 3s 213us/step - loss: 1.8341 - accuracy: 0.7087 - f1_m: 0.7088 - precision_m: 0.7096 - recall_m: 0.7080 - val_loss: 1.9311 - val_accuracy: 0.6061 - val_f1_m: 0.6059 - val_precision_m: 0.6068 - val_recall_m: 0.6050\n",
      "Epoch 289/300\n",
      "12886/12886 [==============================] - 3s 221us/step - loss: 1.8334 - accuracy: 0.7092 - f1_m: 0.7093 - precision_m: 0.7101 - recall_m: 0.7085 - val_loss: 1.8699 - val_accuracy: 0.6735 - val_f1_m: 0.6734 - val_precision_m: 0.6742 - val_recall_m: 0.6726\n",
      "Epoch 290/300\n",
      "12886/12886 [==============================] - 3s 218us/step - loss: 1.8347 - accuracy: 0.7089 - f1_m: 0.7087 - precision_m: 0.7097 - recall_m: 0.7077 - val_loss: 1.8777 - val_accuracy: 0.6654 - val_f1_m: 0.6653 - val_precision_m: 0.6654 - val_recall_m: 0.6652\n",
      "Epoch 291/300\n",
      "12886/12886 [==============================] - 3s 205us/step - loss: 1.8326 - accuracy: 0.7113 - f1_m: 0.7111 - precision_m: 0.7122 - recall_m: 0.7101 - val_loss: 1.9237 - val_accuracy: 0.6179 - val_f1_m: 0.6175 - val_precision_m: 0.6177 - val_recall_m: 0.6173\n",
      "Epoch 292/300\n",
      "12886/12886 [==============================] - 3s 210us/step - loss: 1.8347 - accuracy: 0.7086 - f1_m: 0.7087 - precision_m: 0.7094 - recall_m: 0.7079 - val_loss: 1.9531 - val_accuracy: 0.5906 - val_f1_m: 0.5904 - val_precision_m: 0.5907 - val_recall_m: 0.5902\n",
      "Epoch 293/300\n",
      "12886/12886 [==============================] - 3s 205us/step - loss: 1.8350 - accuracy: 0.7087 - f1_m: 0.7092 - precision_m: 0.7101 - recall_m: 0.7082 - val_loss: 1.8792 - val_accuracy: 0.6589 - val_f1_m: 0.6592 - val_precision_m: 0.6598 - val_recall_m: 0.6587\n",
      "Epoch 294/300\n",
      "12886/12886 [==============================] - 3s 203us/step - loss: 1.8349 - accuracy: 0.7098 - f1_m: 0.7097 - precision_m: 0.7110 - recall_m: 0.7084 - val_loss: 1.9145 - val_accuracy: 0.6300 - val_f1_m: 0.6286 - val_precision_m: 0.6300 - val_recall_m: 0.6272\n",
      "Epoch 295/300\n",
      "12886/12886 [==============================] - 3s 205us/step - loss: 1.8329 - accuracy: 0.7104 - f1_m: 0.7104 - precision_m: 0.7111 - recall_m: 0.7097 - val_loss: 1.8765 - val_accuracy: 0.6623 - val_f1_m: 0.6626 - val_precision_m: 0.6633 - val_recall_m: 0.6620\n",
      "Epoch 296/300\n",
      "12886/12886 [==============================] - 3s 204us/step - loss: 1.8293 - accuracy: 0.7142 - f1_m: 0.7144 - precision_m: 0.7155 - recall_m: 0.7133 - val_loss: 1.8803 - val_accuracy: 0.6620 - val_f1_m: 0.6624 - val_precision_m: 0.6633 - val_recall_m: 0.6615\n",
      "Epoch 297/300\n",
      "12886/12886 [==============================] - 3s 205us/step - loss: 1.8329 - accuracy: 0.7106 - f1_m: 0.7107 - precision_m: 0.7116 - recall_m: 0.7098 - val_loss: 1.9971 - val_accuracy: 0.5385 - val_f1_m: 0.5373 - val_precision_m: 0.5382 - val_recall_m: 0.5364\n",
      "Epoch 298/300\n",
      "12886/12886 [==============================] - 3s 204us/step - loss: 1.8322 - accuracy: 0.7118 - f1_m: 0.7119 - precision_m: 0.7126 - recall_m: 0.7112 - val_loss: 1.8670 - val_accuracy: 0.6744 - val_f1_m: 0.6748 - val_precision_m: 0.6752 - val_recall_m: 0.6743\n",
      "Epoch 299/300\n",
      "12886/12886 [==============================] - 3s 205us/step - loss: 1.8336 - accuracy: 0.7098 - f1_m: 0.7099 - precision_m: 0.7109 - recall_m: 0.7089 - val_loss: 1.8563 - val_accuracy: 0.6844 - val_f1_m: 0.6851 - val_precision_m: 0.6857 - val_recall_m: 0.6845\n",
      "Epoch 300/300\n",
      "12886/12886 [==============================] - 3s 203us/step - loss: 1.8328 - accuracy: 0.7106 - f1_m: 0.7107 - precision_m: 0.7118 - recall_m: 0.7095 - val_loss: 1.9941 - val_accuracy: 0.5462 - val_f1_m: 0.5451 - val_precision_m: 0.5496 - val_recall_m: 0.5409\n"
     ]
    }
   ],
   "source": [
    "resultado = mlp1.fit(xin,labels_hot,validation_split=0.2,epochs=300, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hecto\\AppData\\Local\\Programs\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-653-994b4c9dd8e1>\", line 2, in <module>\n",
      "    mlp1.save('mlp_' + fechaHora)\n",
      "  File \"C:\\Users\\hecto\\AppData\\Local\\Programs\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\", line 1152, in save\n",
      "    save_model(self, filepath, overwrite, include_optimizer)\n",
      "  File \"C:\\Users\\hecto\\AppData\\Local\\Programs\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py\", line 449, in save_wrapper\n",
      "    save_function(obj, filepath, overwrite, *args, **kwargs)\n",
      "  File \"C:\\Users\\hecto\\AppData\\Local\\Programs\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py\", line 541, in save_model\n",
      "    _serialize_model(model, h5dict, include_optimizer)\n",
      "  File \"C:\\Users\\hecto\\AppData\\Local\\Programs\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py\", line 163, in _serialize_model\n",
      "    if isinstance(model.optimizer, optimizers.TFOptimizer):\n",
      "AttributeError: module 'keras.optimizers' has no attribute 'TFOptimizer'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hecto\\AppData\\Local\\Programs\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'AttributeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hecto\\AppData\\Local\\Programs\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\hecto\\AppData\\Local\\Programs\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\hecto\\AppData\\Local\\Programs\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\hecto\\AppData\\Local\\Programs\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\hecto\\AppData\\Local\\Programs\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\hecto\\AppData\\Local\\Programs\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\hecto\\AppData\\Local\\Programs\\Anaconda3\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\hecto\\AppData\\Local\\Programs\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\hecto\\AppData\\Local\\Programs\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\hecto\\AppData\\Local\\Programs\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.optimizers' has no attribute 'TFOptimizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "fechaHora = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "mlp1.save('mlp_' + fechaHora)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'cost')"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.figure(figsize=(10,10))\n",
    "plt.plot(resultado.history['loss'], label=\"Loss\")\n",
    "plt.plot(resultado.history['accuracy'], label=\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"cost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conslusiones\n",
    "\n",
    "La configuracion de los hiperparametros es compleja para lograr resultados altos en las metricas (accuracy, recall, etc) para dataset reales y no datos que se utilizan regularmente para el aprendizaje.  Desde una perspectiva de negocios esto requiere un gran esfuerzo desde todo momento; este proyecto requirio un parte fuerte de *Feature Engineering* lo cual fue muy costoso en tiempo.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Citation\n",
    "\n",
    "\n",
    "1. Yu Zheng, Lizhu Zhang, Xing Xie, Wei-Ying Ma. Mining interesting locations and travel sequences from GPS trajectories. In Proceedings of International conference on World Wild Web (WWW 2009), Madrid Spain. ACM Press: 791-800.\n",
    "\n",
    "2. Yu Zheng, Quannan Li, Yukun Chen, Xing Xie, Wei-Ying Ma. Understanding Mobility Based on GPS Data. In Proceedings of ACM conference on Ubiquitous Computing (UbiComp 2008), Seoul, Korea. ACM Press: 312-321\n",
    "\n",
    "3. Yu Zheng, Xing Xie, Wei-Ying Ma, GeoLife: A Collaborative Social Networking Service among User, location and trajectory. Invited paper, in IEEE Data Engineering Bulletin. 33, 2, 2010, pp. 32-40.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
